# 记忆系统完整面试指南

> 适用于简历项目答辩、技术面试
> 最后更新：2026-01-04

---

## 目录

1. [整体架构](#一整体架构)
2. [存储分层](#二存储分层)
3. [记忆召回策略](#三记忆召回策略)
4. [记忆生产方式](#四记忆生产方式)
5. [记忆快照详解](#五记忆快照详解)
6. [Embedding模型选择](#六embedding模型选择)
7. [向量数据库选择](#七向量数据库选择)
8. [主动记忆vs被动记忆](#八主动记忆vs被动记忆)
9. [数据压缩策略](#九数据压缩策略)
10. [高频面试问题](#十高频面试问题)
11. [快速记忆卡片](#十一快速记忆卡片)

---

## 一、整体架构

### 1.1 设计理念

```
【核心原则】
职责分离：不同类型的记忆用不同的表存储
时效分层：长期记忆 vs 中期记忆（快照）vs 短期记忆（对话上下文）
避免重复：不对历史对话做向量检索，只对快照做向量检索
```

### 1.2 架构全景

```
┌─────────────────────────────────────────────────────────────┐
│                     记忆系统架构                              │
│                                                               │
│  ┌──────────────────────────────────────────────────────┐   │
│  │           长期记忆（关系型数据库）                    │   │
│  │                                                        │   │
│  │  ┌──────────┐  ┌──────────┐  ┌──────────┐          │   │
│  │  │ Profile  │  │Preferences│  │  Tags    │          │   │
│  │  │ 用户画像 │  │ 用户偏好  │  │结构化标签│          │   │
│  │  └──────────┘  └──────────┘  └──────────┘          │   │
│  │                                                        │   │
│  │  - Profile: 用户基本信息（姓名、职业、兴趣...）      │   │
│  │  - Preferences: 用户偏好习惯（空调温度、驾驶偏好） │   │
│  │  - Tags: 结构化标签（家地址、工作地址、联系人）     │   │
│  │                                                        │   │
│  │  召回方式：直接读取（无需检索）                       │   │
│  └──────────────────────────────────────────────────────┘   │
│                                                               │
│  ┌──────────────────────────────────────────────────────┐   │
│  │         中期记忆（向量数据库 + 关系型DB）             │   │
│  │                                                        │   │
│  │  ┌──────────────────────────────────────┐            │   │
│  │  │         Snapshots（对话快照）        │            │   │
│  │  │  - summary: 对话摘要（纯文本）       │            │   │
│  │  │  - embedding: 摘要的向量            │            │   │
│  │  │  - timestamp: 时间戳                │            │   │
│  │  │  - expires_at: 7天后过期            │            │   │
│  │  └──────────────────────────────────────┘            │   │
│  │                                                        │   │
│  │  召回方式：向量语义检索 + 时间衰减                    │   │
│  └──────────────────────────────────────────────────────┘   │
│                                                               │
│  ┌──────────────────────────────────────────────────────┐   │
│  │       短期记忆（LangGraph Checkpointer）              │   │
│  │                                                        │   │
│  │  ┌──────────────────────────────────────┐            │   │
│  │  │       Messages（对话历史）           │            │   │
│  │  │  - 本次对话的所有消息                │            │   │
│  │  │  - LangGraph自动管理                │            │   │
│  │  │  - 用于对话内上下文理解              │            │   │
│  │  └──────────────────────────────────────┘            │   │
│  │                                                        │   │
│  │  召回方式：框架自动加载（无需手动召回）              │   │
│  └──────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘
```

---

## 二、存储分层

### 2.1 Profile表（用户基本信息）

**字段：**
```sql
user_id         -- 用户ID
name            -- 姓名
occupation      -- 职业
interests       -- 兴趣爱好（JSON数组）
mbti            -- MBTI性格类型
age_range       -- 年龄段
created_at      -- 创建时间
updated_at      -- 更新时间
```

**特点：**
- 静态信息，更新频率低
- 直接读取，无需检索
- 用于个性化称呼、推荐

**示例：**
```json
{
  "user_id": "user_123",
  "name": "张三",
  "occupation": "程序员",
  "interests": ["篮球", "阅读"],
  "age_range": "25-35"
}
```

---

### 2.2 Preferences表（用户偏好习惯）

**字段：**
```sql
user_id         -- 用户ID
category        -- 偏好类别（navigation/music/food/vehicle）
key             -- 偏好键
value           -- 偏好值（JSON）
created_at      -- 创建时间
updated_at      -- 更新时间
```

**category分类：**
- `navigation`: 导航偏好（避开高架、最快路线）
- `music`: 音乐偏好（喜欢的类型、歌手）
- `food`: 饮食偏好（喜欢的菜系、口味）
- `vehicle`: 车辆设置（空调温度、座椅位置）

**特点：**
- 半静态，会随用户习惯调整
- 直接读取，无需检索
- 用于决策时自动应用偏好

**示例：**
```json
{
  "navigation": {
    "avoid_highway": true,
    "route_preference": "fastest"
  },
  "vehicle": {
    "ac_temperature": 22,
    "seat_position": 2
  }
}
```

---

### 2.3 Tags表（结构化标签）

**字段：**
```sql
user_id         -- 用户ID
label           -- 标签名（家、公司、对象家）
address         -- 地址
poi_id          -- POI ID
lat/lon         -- 经纬度
use_count       -- 使用次数
last_used       -- 最后使用时间
```

**特点：**
- 动态更新，使用频次高
- 支持精确匹配和模糊搜索
- 用于快速导航

**示例：**
```json
{
  "label": "家",
  "address": "上海市浦东新区XX路XX号",
  "use_count": 25,
  "last_used": "2026-01-04 10:00"
}
```

---

### 2.4 Snapshots表（对话快照）

**字段：**
```sql
id              -- 快照ID
user_id         -- 用户ID
conversation_id -- 会话ID
summary         -- 对话摘要（纯文本，50-100字）
embedding       -- 摘要的向量（1024维）
timestamp       -- 创建时间
expires_at      -- 过期时间（7天后）
```

**特点：**
- 短期记忆，7天过期
- 向量化，支持语义检索
- 对话级粒度，一次对话一个快照

**示例：**
```json
{
  "summary": "用户导航回家（上海市浦东新区XX路），要求避开延安高架，Agent规划了途径XX路的路线，预计25分钟",
  "timestamp": "2026-01-04 14:30",
  "expires_at": "2026-01-11 14:30"
}
```

---

### 2.5 Messages表（对话历史）

**由LangGraph Checkpointer自动管理**

**字段：**
```sql
conversation_id -- 会话ID
message_id      -- 消息ID
role            -- 角色（human/ai/tool）
content         -- 消息内容
timestamp       -- 时间戳
```

**特点：**
- 保存所有对话消息
- **不进行向量化**（这是关键）
- 用于会话恢复、审计日志
- LangGraph自动加载对话内上下文

**重要：** 对话历史**保存但不召回**，召回用快照就够了。

---

## 三、记忆召回策略

### 3.1 召回全流程

```
用户输入："导航回家"
    ↓
【并行召回4路】

1️⃣ Profile召回（用户基本信息）
   - 直接读取：name, occupation等
   - 作用：个性化称呼

2️⃣ Preferences召回（用户偏好）
   - 直接读取：driving_preference, ac_temperature等
   - 作用：决策时自动应用偏好

3️⃣ Tags召回（结构化标签）
   - 意图检测："导航" + "回家" → 查询 home_address
   - 返回：home_address = "上海市浦东新区XX路"

4️⃣ Snapshots召回（对话快照）
   - 向量检索："导航回家"
   - 返回：Top-2相关快照（如"昨天说别走延安高架"）

    ↓
【注入到System Prompt或User Message】
    ↓
【Agent推理 + 工具调用】
```

### 3.2 为什么不需要"长期记忆语义召回"？

**问题：** 是否需要对历史对话消息（Messages）做向量检索？

**答案：** ❌ **不需要，会和快照召回重复**

**对比分析：**

| 维度 | 长期对话消息向量召回 | 快照召回 |
|------|---------------------|---------|
| **粒度** | 消息级别（每条对话） | 对话级别（整次对话摘要） |
| **内容** | 原始对话（冗长） | LLM提炼的精华（简洁） |
| **噪音** | 高（可能召回无关消息） | 低（已过滤） |
| **时效** | 长期保留 | 7天过期 |
| **成本** | 需要维护大量向量 | 向量量少 |

**结论：**
- 快照已经是对话的"压缩精华"
- 7天内的重要信息已经在快照里
- 7天之前的重要信息应该已经沉淀到Profile/Preferences/Tags
- **不需要对历史消息做向量检索，避免重复和噪音**

---

### 3.3 召回示例

**场景：** 用户说"还是走昨天那条路"

```
【召回结果】

Profile召回：
{
  "name": "张三",
  "occupation": "程序员"
}

Preferences召回：
{
  "navigation": {
    "avoid_highway": true
  }
}

Tags召回：
{
  "home_address": "上海市浦东新区XX路XX号"
}

Snapshots召回（向量检索）：
[
  {
    "summary": "用户昨天导航回家，要求避开延安高架，Agent规划了途径XX路的路线",
    "similarity": 0.87,
    "timestamp": "2026-01-03 18:00"
  }
]

【注入到Context】
System Prompt:
"用户张三（程序员），偏好避开高速。昨天导航时要求避开延安高架，走了XX路。"

【Agent推理】
"好的，为您规划途径XX路的路线（避开延安高架），和昨天一样。"
```

---

## 四、记忆生产方式

### 4.1 生产方式分类

```
【4种生产方式】

1️⃣ 初见引导（首次使用）
   - 触发条件：check_profile_initialized() == False
   - 方式：主动询问基本信息
   - 存储位置：Profile + Tags

2️⃣ 被动记忆（对话中检测）
   - 触发条件：用户主动说"我是程序员"、"我老婆叫XX"
   - 方式：LLM通过Prompt判断，调用工具保存
   - 存储位置：Profile/Preferences/Tags

3️⃣ 主动记忆（缺失时询问）
   - 触发条件：检测到关键信息缺失
   - 方式：LLM主动询问用户
   - 存储位置：Profile/Preferences/Tags

4️⃣ 记忆快照（对话结束）
   - 触发条件：对话结束 + has_tool_call == True
   - 方式：LLM总结对话
   - 存储位置：Snapshots（向量化）
```

### 4.2 被动记忆 vs 主动记忆

| 维度 | 被动记忆 | 主动记忆 |
|------|---------|---------|
| **触发** | 用户主动说 | LLM主动问 |
| **示例** | "我是程序员" → 保存 | "你的职业是？" → 询问 |
| **实现** | Prompt引导检测 | Prompt引导判断 + 询问 |
| **优势** | 不打扰用户 | 主动补全画像 |
| **劣势** | 可能遗漏信息 | 可能打扰用户 |

**当前方案：** 以被动记忆为主，主动记忆为辅（通过Prompt控制频率）

---

## 五、记忆快照详解

### 5.1 核心问题

**1. 什么时候生成快照？**

```
触发条件：对话结束 + 有工具调用

if has_tool_call(messages):
    生成快照
else:
    跳过（纯闲聊不生成）
```

**为什么用"工具调用"判断？**
- 调用了工具 = 用户做了实际操作（导航、查天气、开空调）
- 这些对话一定有价值，值得记录
- 纯闲聊（"你好""今天真好"）不生成快照，避免噪音

---

**2. 快照应该包含什么？**

```
【格式】纯文本摘要（50-100字）

示例：
"用户导航回家（上海市浦东新区XX路），要求避开延安高架，Agent规划了途径XX路的路线，预计25分钟"

【不是流水账】
❌ "用户问了天气，Agent回答了上海今天晴天"

【而是关键信息】
✅ "用户查询明天上海天气，提到明天要去浦东机场，需要早点出发"
```

---

**3. 快照的粒度？**

```
【一次对话一个快照】（推荐）
- 对话结束时生成一个摘要
- 简单、够用

【分段快照】（可选，对话超长时）
- 如果对话超过20轮，中间生成阶段性快照
- 成本高，一般不需要
```

---

**4. 快照和长期记忆的关系？**

```
【关系】
快照检测到"用户说家地址是XX"时：

方案A（推荐）：
- 快照只记录"本次对话提到了家地址"
- 另一个流程（被动记忆）实时提取到Tags表

方案B（不推荐）：
- 快照生成时直接更新Tags
- 职责不清晰，容易遗漏
```

**我们的选择：** 方案A，职责分离
- 被动记忆（对话中）：实时写入Tags/Preferences
- 快照（对话后）：生成对话摘要，用于跨对话召回

---

**5. 快照召回策略？**

```
【召回流程】
用户输入 → 向量化 → 在Snapshots表中检索
    ↓
Top-K（如Top-2）
    ↓
时间衰减排序：
score = similarity * time_decay(timestamp)
    ↓
返回最相关的快照
```

**时间衰减：**
```python
def time_decay(timestamp):
    days_ago = (now - timestamp).days
    return 1.0 / (1 + days_ago * 0.2)
    # 今天: 1.0
    # 1天前: 0.83
    # 3天前: 0.62
    # 7天前: 0.42
```

---

### 5.2 快照生成示例

**对话：**
```
用户："导航回家"
AI："好的，目的地是？"
用户："上海市浦东新区XX路"
AI："为您规划路线..."
用户："别走延安高架"
AI："好的，重新规划..."
[调用工具：com_sgm_navi_hmi_plan_route]
AI："已为您规划途径XX路的路线，预计25分钟"
```

**生成快照：**
```
Prompt:
"总结这次对话的关键内容，包括：
1. 用户的需求
2. 重要的偏好/限制
3. Agent的执行结果
保持简洁，50字以内。"

LLM输出：
"用户导航回家（上海市浦东新区XX路），要求避开延安高架，Agent规划了途径XX路的路线，预计25分钟"
```

**存储：**
```json
{
  "user_id": "user_123",
  "conversation_id": "conv_456",
  "summary": "用户导航回家（上海市浦东新区XX路），要求避开延安高架，Agent规划了途径XX路的路线，预计25分钟",
  "embedding": [0.1, 0.2, ...],  // summary的向量
  "timestamp": "2026-01-04 14:35",
  "expires_at": "2026-01-11 14:35"  // 7天后过期
}
```

---

## 六、Embedding模型选择

### 6.1 核心考量维度

```
【性能三角】
     召回准确性
        /\
       /  \
      /    \
   速度 ---- 成本
```

### 6.2 模型分类

| 类型 | 模型示例 | 维度 | 速度 | 准确性 | 适用场景 |
|------|----------|------|------|--------|----------|
| **小模型** | text2vec-base-chinese | 768 | 快（<5ms） | 中 | 端侧部署 |
| **中模型** | bge-large-zh-v1.5 | 1024 | 中（10-20ms） | 高 | 云端部署（推荐） |
| **大模型** | text-embedding-3-large | 3072 | 慢（50ms+） | 最高 | 高精度需求 |

### 6.3 推荐方案

**基于车载场景（云端部署、中文、实时召回）：**

```
【推荐模型】
bge-large-zh-v1.5

【理由】
1. 中文语义理解强（智源研究院专门针对中文优化）
2. 维度适中（1024）：准确性和速度平衡
3. 开源免费，无调用费用
4. 速度够快（GPU推理 10-15ms）
5. 社区成熟，文档齐全

【部署】
云端与Agent同机部署
```

**代码示例：**
```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('BAAI/bge-large-zh-v1.5')

# 生成embedding
text = "用户导航回家，要求避开延安高架"
embedding = model.encode(text)  # 1024维向量
```

### 6.4 备选方案

**如果bge召回不准：**
```
方案1：加入重排序（Rerank）
- 召回Top-10（用bge）
- 重排序到Top-2（用bge-reranker-large）
- 提升准确性，成本增加不多

方案2：换更大的模型
- OpenAI text-embedding-3-large（3072维）
- 准确性最高，但成本高、速度慢
```

**如果需要多语言：**
```
multilingual-e5-large
- 支持100+语言
- 中文效果不如bge，但够用
```

---

## 七、向量数据库选择

### 7.1 选型对比

| 数据库 | 类型 | 优势 | 劣势 | 适用场景 |
|--------|------|------|------|----------|
| **Chroma** | 嵌入式 | 轻量、易用、Python原生 | 单机，不支持分布式 | POC、小规模（推荐） |
| **Faiss** | 库 | 性能极强、GPU加速、索引丰富 | 需要手动管理持久化 | 生产环境、性能敏感 |
| **Milvus** | 分布式 | PB级、高可用、企业级 | 重量级，部署复杂 | 大规模（用不到） |
| **Qdrant** | 分布式 | Rust实现、性能好、易用 | 社区较小 | 中大规模 |

### 7.2 推荐方案

**基于快照量级（7天，<100条）：**

```
【POC阶段】
Chroma
- 轻量级，嵌入式部署
- Python原生，集成简单
- 支持自动持久化

【生产阶段】
Faiss
- Meta开源，性能极强
- 支持GPU加速
- 索引算法丰富（HNSW、IVF）
- 需要手动管理持久化（可以配合SQLite）
```

**代码示例（Chroma）：**
```python
import chromadb

client = chromadb.Client()
collection = client.create_collection("snapshots")

# 插入快照
collection.add(
    documents=["用户导航回家，要求避开延安高架"],
    metadatas=[{"user_id": "user_123", "timestamp": "2026-01-04"}],
    ids=["snapshot_1"]
)

# 检索
results = collection.query(
    query_texts=["导航回家"],
    n_results=2
)
```

---

## 八、主动记忆vs被动记忆

### 8.1 问题背景

**被动记忆的局限：**
```
用户："我是程序员" → LLM检测到 → 保存 ✅
用户：... 从不提职业 → LLM检测不到 → 画像空白 ❌
```

**主动记忆的价值：**
```
LLM主动询问："请问您的职业是？"
用户："程序员" → 保存 ✅
```

### 8.2 实现方式对比

| 方式 | 成本 | 效果 | 现在能用 | 面试能说 |
|------|------|------|---------|---------|
| **Prompt工程** | 低 | 中上 | ✅ 主力 | ✅ 当前方案 |
| **规则触发** | 低 | 中 | ✅ 辅助 | ⚠️ 不够智能 |
| **两阶段架构** | 中 | 高 | ⚠️ 可选 | ✅ 优化方向 |
| **微调** | 高 | 最高 | ❌ 暂无 | ✅ 未来方向 |
| **RLHF** | 极高 | 理论最优 | ❌ 不考虑 | ⚠️ 了解即可 |

### 8.3 推荐方案：Prompt工程

**核心思路：** 赋予LLM"判断什么值得主动记忆"的能力

**System Prompt设计：**
```
你是车载AI助手，拥有主动记忆能力。

【主动记忆原则】
当用户在对话中透露了可能对未来有用的信息时，你应该主动判断是否值得保存。

判断标准：
1. 是否是重复性的偏好/习惯？（值得保存）
   - "我不喜欢走高架" ✅（长期偏好）
   - "今天不走高架" ❌（一次性）

2. 是否是长期有效的信息？（值得保存）
   - "我不吃辣" ✅（长期偏好）
   - "明天不吃辣" ❌（一次性）

3. 是否是用户明确的关系/地址？（值得保存）
   - "我朋友张三住XX" ✅
   - "路过XX看到张三" ❌

如果判断值得保存：
- 自然地询问用户："要不要我记住这个偏好/信息？"
- 用户同意后，调用相应的记忆工具

重要：
- 不要频繁打扰用户（一次对话最多问1-2次）
- 用户拒绝后，本次对话不再追问
- 语气要自然，不要生硬
```

**对话示例：**
```
【场景1：路线偏好】
用户："这条延安路太堵了，下次别走了"

LLM推理：
- "下次"暗示长期偏好
- 值得主动询问

LLM回复："好的，下次避开延安路。要不要我永久记住您不喜欢走这条路？"

用户："好啊"
→ 调用 memory_save_preference(category="navigation", key="avoid_延安路", value="true")

【场景2：一次性事件（不该问）】
用户："明天要去机场，7点出发"

LLM推理：
- 一次性行程安排
- 不值得长期保存

LLM回复："好的，明天7点出发去机场，我会提醒您的"
→ 不调用记忆工具（或存临时上下文）
```

### 8.4 为什么不用规则触发？

**规则触发的问题：**
```
场景1："导航回家" → 检测到 → 问地址 ✅
场景2："这条路太堵了" → 检测不到 ❌
场景3："这家餐厅不错" → 检测不到 ❌
场景4："我不吃香菜" → 检测不到 ❌
场景5："每周五要去健身房" → 检测不到 ❌

值得记忆的场景太多，规则穷举不完！
```

**LLM判断的优势：**
- 理解上下文（"明天不走" vs "下次不走"）
- 覆盖长尾场景（不需要穷举）
- 自然、智能

### 8.5 控制策略（避免骚扰）

```python
【频率限制】
- 单次对话最多主动询问2次
- 用户拒绝后，本次对话不再追问
- 相同类型的询问，一天最多1次

【优先级】
高优先级（关键信息）：
- 家庭地址、工作地址
- 紧急联系人

低优先级（辅助信息）：
- 餐厅偏好
- 音乐口味

如果检测到多个值得保存的信息，优先询问高优先级的。
```

---

## 九、数据压缩策略

### 9.1 两种压缩

**压缩1️⃣：对话历史压缩（上下文管理）**

**问题：**
```
用户和AI聊了50轮，messages表有100条消息
    ↓
下一轮对话，要把100条都塞给LLM？
    ↓
Context太长：
- Token成本高
- 推理慢
- 可能超出LLM上下文窗口
```

**解决方案：**

| 方案 | 做法 | 优势 | 劣势 |
|------|------|------|------|
| **滑动窗口** | 只保留最近N轮（如10轮） | 简单 | 丢失早期重要信息 |
| **重要性过滤** | 保留System/最近3轮/工具调用消息 | 保留关键信息 | 需要定义过滤规则 |
| **LLM摘要**（推荐） | 每10轮 → LLM总结 → 注入摘要 | 不丢失重要信息 | 需要调用LLM |

**LLM摘要方案：**
```
【流程】
对话进行到第10轮：
    ↓
调用LLM总结前10轮：
"总结这10轮对话的关键信息，包括用户需求、已完成的操作、未解决的问题"
    ↓
生成摘要消息：
"用户询问了天气、导航到家、查询了附近餐厅。当前未完成：预订餐厅。"
    ↓
新的Context:
[SystemMessage] + [摘要Message] + [最近3轮] → 注入LLM
```

**这个压缩发生在哪？**
- 在Agent推理之前
- **不是记忆模块的一部分**
- 是上下文管理（Context Management）

---

**压缩2️⃣：记忆快照本身就是压缩**

**完整对话 → 快照摘要**

```
【原始对话】（20轮，2000字）
用户："导航回家"
AI："好的，目的地是？"
用户："上海市浦东新区XX路"
AI："为您规划路线..."
用户："别走延安高架"
AI："好的，重新规划..."
...（省略15轮）

    ↓ LLM总结

【快照】（50字）
"用户导航回家（上海市浦东新区XX路），要求避开延安高架，Agent规划了途径XX路的路线"
```

**快照的本质：有损压缩**
- 保留关键信息（目的地、偏好、结果）
- 丢弃冗余信息（重复确认、礼貌用语）

**这个压缩是记忆模块的一部分。**

---

### 9.2 对话历史 vs 快照的分工

```
【对话历史（Messages）】
- 保存：✅ 必须保存（LangGraph自动）
- 向量化：❌ 不需要
- 用途：会话恢复、审计日志、对话内上下文

【快照（Snapshots）】
- 保存：✅ 对话结束时生成
- 向量化：✅ 需要（用于召回）
- 用途：跨对话上下文召回
```

**关键点：**
- 对话历史保存但不用于召回
- 召回用快照（已经是压缩后的精华）
- 避免重复和噪音

---

## 十、高频面试问题

### Q1: 你的记忆系统架构是怎样的？

**标准答案：**
```
我们的记忆系统采用分层架构，避免重复和职责混乱：

1. 长期记忆（关系型DB）：
   - Profile: 用户基本信息（姓名、职业）
   - Preferences: 用户偏好习惯（空调温度、驾驶偏好）
   - Tags: 结构化标签（家地址、联系人）
   - 召回方式：直接读取，无需检索

2. 中期记忆（向量DB + 关系DB）：
   - Snapshots: 对话快照（7天过期）
   - 召回方式：向量语义检索 + 时间衰减

3. 短期记忆（LangGraph Checkpointer）：
   - Messages: 对话历史
   - 召回方式：框架自动加载

关键设计：不对历史消息做向量检索，只对快照做向量检索，避免重复。
```

---

### Q2: 为什么不对历史对话做语义召回？

**标准答案：**
```
这会和快照召回重复，且噪音更大：

对比：
- 历史消息：消息级粒度，冗长，噪音高
- 快照：对话级粒度，已提炼，噪音低

逻辑：
- 7天内的重要信息 → 已经在快照里
- 7天之前的重要信息 → 应该已经沉淀到Profile/Preferences/Tags
- 不重要的信息 → 不需要召回

所以只需要对快照做向量检索就够了。
```

---

### Q3: 快照什么时候生成？

**标准答案：**
```
触发条件：对话结束 + 有工具调用

原因：
- 调用了工具 = 用户做了实际操作（导航、查天气、车控）
- 这些对话一定有价值
- 纯闲聊（"你好""今天真好"）不生成，避免噪音

优势：
- 简单明确（零成本判断）
- 准确率高（避免无用快照）
```

---

### Q4: 为什么选择bge-large-zh-v1.5？

**标准答案：**
```
基于场景匹配和性价比：

1. 场景匹配：
   - 车载场景纯中文，bge专门针对中文优化
   - MTEB中文榜单排名靠前

2. 性能平衡：
   - 1024维，准确性和速度平衡
   - GPU推理10-15ms，满足实时召回需求

3. 成本考虑：
   - 开源免费，无调用费用
   - 云端部署一次，无边际成本

4. 工程可行性：
   - 社区成熟，文档齐全
   - sentence-transformers库直接支持
```

---

### Q5: 如果快照召回不准怎么办？

**标准答案：**
```
分两个层面优化：

1. 策略层面（优先尝试）：
   - 加入重排序：召回Top-10，用reranker重排到Top-2
   - 混合召回：向量召回 + 关键词召回，融合排序
   - 加权调整：时间衰减、实体匹配加权

2. 模型层面（成本高）：
   - 换更大的模型（bge-large → text-embedding-3-large）
   - 领域微调（用车载对话数据fine-tune）

关键：不要一上来就说换模型，先说策略优化。
```

---

### Q6: 主动记忆怎么实现？

**标准答案：**
```
我们采用Prompt工程，赋予LLM自主判断能力：

方案：
1. 在System Prompt中定义"主动记忆原则"
2. 教会LLM区分"一次性信息" vs "长期偏好"
3. 用Few-shot引导LLM做正确判断

为什么不用规则？
- 值得记忆的场景太多，规则穷举不完
- 需要理解上下文（"明天不走" vs "下次不走"）
- 规则无法应对长尾场景

为什么信任LLM？
- 现代LLM的上下文理解能力已经很强
- Few-shot可以稳定引导行为
- 即使误判，影响可控（最多多问一次）

控制策略：
- 单次对话最多问2次
- 用户拒绝后不再追问
- 关键信息（地址、联系人）优先级更高
```

---

### Q7: embedding维度高低有什么影响？

**标准答案：**
```
维度是信息密度和计算成本的权衡：

高维度（1536-3072）：
✅ 语义信息更丰富，细微差别捕捉更好
❌ 存储成本高（向量数据库索引大）
❌ 检索速度稍慢（距离计算复杂度O(d)）

低维度（384-768）：
✅ 检索快
✅ 存储小
❌ 语义表达能力有限

我们的场景（7天快照，几十条）：
- 量级小 → 维度影响不大
- 选1024（中等）足够，无需3072
```

---

### Q8: 对话历史和快照的区别？

**标准答案：**
```
两者职责不同：

对话历史（Messages）：
- 粒度：消息级别（每条对话）
- 内容：原始对话（完整、冗长）
- 保存：✅ 必须保存
- 向量化：❌ 不需要
- 用途：会话恢复、审计日志、对话内上下文

快照（Snapshots）：
- 粒度：对话级别（整次对话摘要）
- 内容：LLM提炼的关键信息（简洁）
- 保存：✅ 对话结束时生成
- 向量化：✅ 需要
- 用途：跨对话上下文召回

关键：对话历史保存但不召回，召回用快照。
```

---

### Q9: 为什么快照只保留7天？

**标准答案：**
```
基于时效性和存储成本权衡：

1. 时效性：
   - 7天内的对话上下文最有价值
   - 7天之前的重要信息应该已经沉淀到长期记忆

2. 存储成本：
   - 向量数据量小，检索快
   - 避免累积大量无用快照

3. 用户习惯：
   - 车载场景，用户很少提"一个月前说过的话"
   - 7天覆盖大部分场景

如果需要更长时间，可以调整为30天，但成本增加。
```

---

### Q10: 如何避免重复保存记忆？

**标准答案：**
```
在Prompt中明确规则：

防止重复调用的关键原则：
1. 检查对话历史：之前是否已经为相同信息调用过工具
2. 检查当前内容：用户是否在重复之前说过的信息
3. 一次对话中同一信息只调用一次工具

示例：
第1轮：用户说"我朋友张三住长阳路1900弄"
     → 调用 memory_save_relationship ✅

第2轮：用户说"是"（确认保存）
     → 不再调用工具 ❌（已经调用过了）

通过Prompt教育LLM这个规则。
```

---

### Q11: 向量数据库怎么选？

**标准答案：**
```
基于我们的场景（7天快照，<100条）：

POC阶段：Chroma
✅ 轻量级，嵌入式部署
✅ Python原生，集成简单
✅ 支持自动持久化
❌ 单机，不支持分布式

生产阶段：Faiss
✅ Meta开源，性能极强
✅ 支持GPU加速
✅ 索引算法丰富（HNSW、IVF）
❌ 需要手动管理持久化

大规模场景：Milvus / Qdrant
✅ 分布式，支持PB级
❌ 我们用不到，太重

我们选Chroma或Faiss，看团队熟悉度。
```

---

### Q12: 记忆系统还有哪些优化方向？

**标准答案：**
```
短期优化（当前可做）：
1. 快照质量提升：引入重要性评分，过滤低价值快照
2. 召回策略优化：加入重排序、混合召回
3. 主动记忆优化：用两阶段架构（对话后分析）

中期优化（产品化阶段）：
1. 记忆纠错机制：检测冲突信息，主动确认
2. 记忆自动归档：冷热分离，降低存储成本
3. 个性化推送：基于记忆的主动服务

长期优化（大规模阶段）：
1. 微调记忆判断模型：提升主动记忆准确率
2. RLHF优化：最大化用户接受率
3. 多模态记忆：支持图片、语音记忆
```

---

## 十一、快速记忆卡片

### 30秒版本（电梯演讲）

```
我们的记忆系统采用分层架构：

1. 长期记忆（Profile/Preferences/Tags）：直接读取
2. 中期记忆（Snapshots）：向量检索，7天过期
3. 短期记忆（Messages）：LangGraph自动管理

关键设计：
- 不对历史消息做向量检索，只对快照做
- 快照生成条件：对话结束 + 有工具调用
- Embedding模型：bge-large-zh-v1.5
- 主动记忆：Prompt工程赋予LLM判断能力
```

### 1分钟版本（面试开场）

```
记忆系统是车载AI的核心能力，我们设计了三层架构：

【长期记忆】
- Profile: 用户基本信息
- Preferences: 用户偏好习惯
- Tags: 结构化标签（地址、联系人）
- 召回：直接读取，无需检索

【中期记忆】
- Snapshots: 对话快照（7天过期）
- 召回：向量语义检索 + 时间衰减
- Embedding: bge-large-zh-v1.5（1024维）
- 向量DB: Chroma（POC）或 Faiss（生产）

【短期记忆】
- Messages: 对话历史
- 管理：LangGraph自动加载

【关键设计】
1. 避免重复：不对历史消息做向量检索，只对快照做
2. 快照生成：对话结束 + 有工具调用
3. 主动记忆：Prompt工程 + Few-shot引导
4. 数据压缩：快照本身就是对话的压缩精华

【优化方向】
- 短期：重排序、混合召回
- 中期：微调记忆判断模型
- 长期：RLHF、多模态记忆
```

---

## 附录：关键公式和伪代码

### A1. 时间衰减公式

```python
def time_decay(timestamp):
    """计算时间衰减系数"""
    days_ago = (now - timestamp).days
    return 1.0 / (1 + days_ago * 0.2)
```

### A2. 快照召回伪代码

```python
def recall_snapshots(user_input, user_id, top_k=2):
    """召回相关快照"""
    # 1. 向量化用户输入
    query_embedding = embedding_model.encode(user_input)

    # 2. 向量检索（最近7天）
    snapshots = vector_db.search(
        query_embedding=query_embedding,
        filter={"user_id": user_id, "expires_at": ">= now()"},
        top_k=top_k * 2  # 先召回多一些
    )

    # 3. 时间衰减排序
    for snapshot in snapshots:
        decay = time_decay(snapshot.timestamp)
        snapshot.score = snapshot.similarity * decay

    # 4. 重排序并返回Top-K
    snapshots.sort(key=lambda x: x.score, reverse=True)
    return snapshots[:top_k]
```

### A3. 快照生成伪代码

```python
def generate_snapshot(messages, user_id, conversation_id):
    """生成对话快照"""
    # 1. 判断是否需要生成
    if not has_tool_call(messages):
        return None  # 没有工具调用，跳过

    # 2. 调用LLM总结
    prompt = """总结这次对话的关键内容，包括：
    1. 用户的需求
    2. 重要的偏好/限制
    3. Agent的执行结果
    保持简洁，50字以内。"""

    summary = llm.invoke(prompt, messages)

    # 3. 向量化
    embedding = embedding_model.encode(summary)

    # 4. 保存到数据库
    snapshot = {
        "user_id": user_id,
        "conversation_id": conversation_id,
        "summary": summary,
        "embedding": embedding,
        "timestamp": now(),
        "expires_at": now() + timedelta(days=7)
    }

    db.insert("snapshots", snapshot)
    return snapshot
```

---

**文档版本**: v1.0
**最后更新**: 2026-01-04
**维护者**: [Your Name]

---

## 使用建议

**面试前30分钟：**
1. 看"快速记忆卡片"（30秒版本 + 1分钟版本）
2. 过一遍"高频面试问题"的标准答案

**面试前1天：**
1. 完整阅读一遍全文
2. 重点看"整体架构"和"存储分层"
3. 理解"为什么不需要长期记忆语义召回"

**深入准备：**
1. 阅读全文2-3遍
2. 理解每个设计决策的trade-off
3. 准备1-2个"踩坑经验"（参考高频问题Q5）

祝面试顺利！🚀
