"""Chat API æ¥å£"""
from fastapi import APIRouter, Request, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from typing import List, Optional, Any, Iterable, Dict, Set
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
import json
import asyncio
import time
import uuid

# HITL æ”¯æŒ
from langgraph.types import Command

# Agentä»app.stateä¸­è·å–ï¼Œä¸éœ€è¦å¯¼å…¥
from ..config import config
from ..db.database import update_conversation_activity, ensure_conversation_exists
from ..db.models import ConversationCreate
from ..utils.structured_logger import get_logger, LogContext
from ..langfuse_config import create_langfuse_handler

# è·å–logger
logger = get_logger(__name__)

router = APIRouter()


class ImageData(BaseModel):
    """å›¾ç‰‡æ•°æ®"""
    type: str = Field(default="base64", description="å›¾ç‰‡ç±»å‹: base64 æˆ– url")
    data: str = Field(..., description="Base64ç¼–ç çš„å›¾ç‰‡æ•°æ®æˆ–URL")


class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚"""
    message: str
    user_id: str = "user_001"  # ç”¨æˆ·IDï¼ˆå½“å‰å›ºå®šä¸ºuser_001ï¼‰
    conversation_id: str = "default"  # å¯¹è¯IDï¼ˆå¯¹åº”LangGraphçš„thread_idï¼‰
    images: Optional[List[ImageData]] = Field(default=None, description="å›¾ç‰‡åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰")


class ChatResponse(BaseModel):
    """èŠå¤©å“åº”"""
    response: str
    conversation_id: str


class ResumeRequest(BaseModel):
    """æ¢å¤ä¸­æ–­è¯·æ±‚"""
    conversation_id: str = Field(..., description="å¯¹è¯ID")
    user_id: str = Field(default="user_001", description="ç”¨æˆ·ID")
    resume_value: Any = Field(..., description="ç”¨æˆ·å“åº”å€¼ï¼ˆç¡®è®¤/é€‰æ‹©/å‚æ•°ï¼‰")


def build_message(text: str, images: Optional[List[ImageData]] = None) -> HumanMessage:
    """
    æ„å»º LangChain æ¶ˆæ¯ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰

    Args:
        text: æ–‡æœ¬å†…å®¹
        images: å›¾ç‰‡åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰

    Returns:
        HumanMessage: LangChain æ¶ˆæ¯å¯¹è±¡
    """
    if not images or len(images) == 0:
        # çº¯æ–‡æœ¬æ¶ˆæ¯
        return HumanMessage(content=text)

    # å¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆå›¾ç‰‡ + æ–‡æœ¬ï¼‰
    content = []

    # æ·»åŠ æ–‡æœ¬éƒ¨åˆ†
    if text and text.strip():
        content.append({
            "type": "text",
            "text": text
        })

    # æ·»åŠ å›¾ç‰‡éƒ¨åˆ†
    for img in images:
        if img.type == "base64":
            # Base64æ ¼å¼
            # ç¡®ä¿dataåŒ…å«å®Œæ•´çš„data URIæ ¼å¼
            image_data = img.data
            if not image_data.startswith("data:"):
                # å¦‚æœæ²¡æœ‰data URIå‰ç¼€ï¼Œæ·»åŠ é»˜è®¤çš„
                image_data = f"data:image/jpeg;base64,{image_data}"

            content.append({
                "type": "image_url",
                "image_url": {
                    "url": image_data
                }
            })
        elif img.type == "url":
            # URLæ ¼å¼
            content.append({
                "type": "image_url",
                "image_url": {
                    "url": img.data
                }
            })

    return HumanMessage(content=content)


def _flatten_text(value: Any) -> Iterable[str]:
    """ä»å¤šç§è¿”å›ç»“æ„ä¸­æå–çº¯æ–‡æœ¬ï¼Œå…¼å®¹ LangChain/BaseMessageã€dictã€list.

    æ³¨æ„ï¼šä¼šè‡ªåŠ¨è¿‡æ»¤ToolMessageï¼ˆå·¥å…·çš„åŸå§‹è¿”å›ï¼‰ï¼Œåªæå–AIMessageçš„ï¿½ï¿½ï¿½å®¹
    """
    if value is None:
        return []

    # âœ… LangChain Message å¯¹è±¡ - è·³è¿‡ToolMessage
    if isinstance(value, ToolMessage):
        return []  # ä¸æ˜¾ç¤ºå·¥å…·çš„åŸå§‹è¿”å›

    content = getattr(value, "content", None)
    if content is not None:
        if isinstance(content, str):
            return [content]
        if isinstance(content, list):
            texts: List[str] = []
            for item in content:
                texts.extend(_flatten_text(item))
            return texts
        return [str(content)]

    if isinstance(value, str):
        # è¿‡æ»¤LangGraphçš„å†…éƒ¨å¸¸é‡å’Œç©ºå­—ç¬¦ä¸²
        if value in ["__end__", "__start__", ""] or not value.strip():
            return []
        return [value]

    if isinstance(value, list):
        texts: List[str] = []
        for item in value:
            texts.extend(_flatten_text(item))
        return texts

    if isinstance(value, dict):
        # LangGraph èŠ‚ç‚¹è¾“å‡ºé€šå¸¸åŒ…å« messages / output ç­‰å­—æ®µ
        if "messages" in value:
            texts: List[str] = []
            for item in value["messages"]:
                # âœ… è¿‡æ»¤ToolMessage
                if not isinstance(item, ToolMessage):
                    texts.extend(_flatten_text(item))
            return texts
        if "output" in value:
            return list(_flatten_text(value["output"]))
        if "content" in value:
            return list(_flatten_text(value["content"]))

        # âš ï¸ å¿½ç•¥çŠ¶æ€å­—æ®µï¼ˆtotal_tool_calls, force_terminate, iteration_countç­‰ï¼‰
        # è¿™äº›å­—æ®µä¸åº”è¯¥è¢«å½“ä½œæ¶ˆæ¯å†…å®¹
        # å¦‚æœæ²¡æœ‰messages/output/contentå­—æ®µï¼Œè¿”å›ç©ºåˆ—è¡¨
        return []

    return [str(value)]


@router.post("/chat", response_model=ChatResponse)
async def chat(chat_request: ChatRequest, request: Request):
    """æ ‡å‡† Chat æ¥å£ï¼ˆéæµå¼ï¼‰"""

    # ä» app.state è·å–Agent
    agent = request.app.state.agent

    # é…ç½® Checkpointingï¼ˆä½¿ç”¨ conversation_id ä½œä¸º thread_idï¼‰
    config = {"configurable": {"thread_id": chat_request.conversation_id, "user_id": chat_request.user_id}}

    # æ„é€ åˆå§‹çŠ¶æ€ï¼ˆåŒ…å«æ¶ˆæ¯å’Œè®¡æ•°å™¨ï¼‰
    initial_state = {
        "messages": [build_message(chat_request.message, chat_request.images)],
        "iteration_count": 0,      # åˆå§‹åŒ–å¾ªç¯è®¡æ•°å™¨
        "total_tool_calls": 0,     # åˆå§‹åŒ–å·¥å…·è°ƒç”¨è®¡æ•°å™¨
        "force_terminate": False,  # åˆå§‹åŒ–å¼ºåˆ¶ç»ˆæ­¢æ ‡è®°
    }

    # è¿è¡Œ Agent
    final_state = await agent.ainvoke(initial_state, config)

    # æå–æœ€ç»ˆå“åº”ï¼ˆåªä¿ç•™AIæ¶ˆæ¯ï¼‰
    response_messages = []
    for msg in final_state["messages"]:
        # åªæå–AIçš„å›å¤
        if isinstance(msg, AIMessage):
            content = msg.content

            # å¤„ç†å¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆcontentå¯èƒ½æ˜¯åˆ—è¡¨ï¼‰
            if isinstance(content, str):
                if content.strip():  # è·³è¿‡ç©ºå†…å®¹
                    response_messages.append(content)
            elif isinstance(content, list):
                # å¤šæ¨¡æ€æ¶ˆæ¯ï¼Œæå–æ–‡æœ¬éƒ¨åˆ†
                text_parts = [item.get("text", "") for item in content if isinstance(item, dict) and item.get("type") == "text"]
                if text_parts:
                    response_messages.append(" ".join(text_parts))
            else:
                response_messages.append(str(content))

    # åªè¿”å›æœ€åä¸€æ¡AIå›å¤
    final_response = response_messages[-1] if response_messages else "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç”Ÿæˆå›å¤ã€‚"

    # æ›´æ–°å¯¹è¯æ´»åŠ¨
    await update_conversation_activity(chat_request.conversation_id, chat_request.message)

    return ChatResponse(
        response=final_response,
        conversation_id=chat_request.conversation_id
    )


@router.post("/chat/stream")
async def chat_stream(chat_request: ChatRequest, request: Request):
    """SSE æµå¼ Chat æ¥å£ - çœŸæ­£çš„LLMæµå¼è¾“å‡º"""

    user_message = chat_request.message
    conversation_id = chat_request.conversation_id
    user_id = chat_request.user_id

    # ç”Ÿæˆå”¯ä¸€è¯·æ±‚ID
    request_id = str(uuid.uuid4())

    async def event_generator():
        """ç”Ÿæˆ SSE äº‹ä»¶"""
        # âœ… è®¾ç½®æ—¥å¿—ä¸Šä¸‹æ–‡ï¼ˆè‡ªåŠ¨ä¼ æ’­åˆ°æ‰€æœ‰å­è°ƒç”¨ï¼‰
        with LogContext(
            request_id=request_id,
            conversation_id=conversation_id,
            user_id=user_id
        ):
            try:
                # âœ… è®°å½•è¯·æ±‚å¼€å§‹
                logger.info(
                    "æ”¶åˆ°èŠå¤©è¯·æ±‚",
                    endpoint="/chat/stream",
                    message_length=len(user_message),
                    has_images=bool(chat_request.images),
                    image_count=len(chat_request.images) if chat_request.images else 0
                )

                # âœ… ç¡®ä¿å¯¹è¯è®°å½•å­˜åœ¨ï¼ˆå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»ºï¼‰
                await ensure_conversation_exists(conversation_id, user_id, "æ–°å¯¹è¯")

                # å‘é€å¼€å§‹äº‹ä»¶
                yield f"data: {json.dumps({'type': 'start', 'message': 'å¼€å§‹å¤„ç†...'}, ensure_ascii=False)}\n\n"

                # ä» app.state è·å–Agent
                agent = request.app.state.agent

                # âœ… åˆ›å»ºç‹¬ç«‹çš„ LangFuse handlerï¼ˆv3.x å®˜æ–¹æ–¹å¼ï¼‰
                langfuse_handler, langfuse_metadata = create_langfuse_handler(
                    session_id=conversation_id,
                    user_id=user_id,
                    tags=["production", "navigation"],
                    metadata={
                        "has_images": bool(chat_request.images),
                        "image_count": len(chat_request.images) if chat_request.images else 0
                    }
                )

                # é…ç½® Checkpointing å’Œ LangFuse
                config = {
                    "configurable": {
                        "thread_id": conversation_id,
                        "user_id": user_id
                    }
                }

                # âœ… v3.x: é€šè¿‡ metadata ä¼ é€’ session_id å’Œ user_id
                if langfuse_handler and langfuse_metadata:
                    config["callbacks"] = [langfuse_handler]
                    config["metadata"] = langfuse_metadata

                # æ„é€ åˆå§‹çŠ¶æ€ï¼ˆåŒ…å«æ¶ˆæ¯å’Œè®¡æ•°å™¨ï¼‰
                initial_state = {
                    "messages": [build_message(user_message, chat_request.images)],
                    "iteration_count": 0,      # åˆå§‹åŒ–å¾ªç¯è®¡æ•°å™¨
                    "total_tool_calls": 0,     # åˆå§‹åŒ–å·¥å…·è°ƒç”¨è®¡æ•°å™¨
                    "force_terminate": False,  # åˆå§‹åŒ–å¼ºåˆ¶ç»ˆæ­¢æ ‡è®°
                }

                # çŠ¶æ€è·Ÿè¸ª
                current_node = None
                current_message = ""
                seen_nodes = set()  # ç”¨äºèŠ‚ç‚¹äº‹ä»¶å»é‡ï¼ˆä»…ç”¨äºnode_startæ¶ˆæ¯ï¼‰
                node_sent_texts: Dict[str, Set[str]] = {}

                def detect_node(event, fallback=None):
                    """æ ¹æ®äº‹ä»¶å…ƒæ•°æ®æå–å½“å‰èŠ‚ç‚¹åç§°"""
                    metadata = event.get("metadata", {}) or {}
                    tags = event.get("tags", []) or []

                    node_name = metadata.get("langgraph_node") or metadata.get("node")
                    if node_name:
                        return node_name

                    for tag in tags:
                        if tag.startswith("langgraph_node:"):
                            return tag.split(":", 1)[1]

                    return fallback

                # âœ… ä½¿ç”¨ Agent çš„ astream_events è·å–çœŸæ­£çš„æµå¼è¾“å‡º
                # âœ… æ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼ˆ2åˆ†é’Ÿï¼‰
                start_time = time.time()
                graph_finished = False  # æ ‡è®° graph æ˜¯å¦å®Œæˆæ‰§è¡Œ

                async for event in agent.astream_events(initial_state, config):
                    # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
                    elapsed = time.time() - start_time
                    if elapsed > 120:  # 2åˆ†é’Ÿ
                        print(f"\n{'='*60}")
                        print(f"[Stream] âš ï¸ Agentæ‰§è¡Œè¶…æ—¶ï¼")
                        print(f"[Stream] ğŸ“Š å·²æ‰§è¡Œæ—¶é—´: {elapsed:.2f} ç§’")
                        print(f"[Stream] ğŸ“Š è¶…æ—¶é™åˆ¶: 120 ç§’ï¼ˆ2åˆ†é’Ÿï¼‰")
                        print(f"[Stream] ğŸš« å¼ºåˆ¶ç»ˆæ­¢æ‰§è¡Œ")
                        print(f"{'='*60}\n")
                        yield f"data: {json.dumps({'type': 'error', 'message': 'ä»»åŠ¡æ‰§è¡Œè¶…æ—¶ï¼ˆ2åˆ†é’Ÿï¼‰ï¼Œå·²å¼ºåˆ¶ç»ˆæ­¢'}, ensure_ascii=False)}\n\n"
                        break

                    event_type = event["event"]
                    event_name = event.get("name", "")

                    # ä»äº‹ä»¶ä¸­è§£æèŠ‚ç‚¹åç§°
                    node_from_tags = detect_node(event)

                    # 1. èŠ‚ç‚¹å¼€å§‹äº‹ä»¶
                    if event_type == "on_chain_start" and node_from_tags:
                        # æ›´æ–° current_node
                        current_node = node_from_tags
                        current_message = ""

                        # â­ è°ƒè¯•æ—¥å¿—
                        print(f"[Stream DEBUG] èŠ‚ç‚¹å¼€å§‹: {node_from_tags}")

                        # åªåœ¨ç¬¬ä¸€æ¬¡è¿›å…¥æ—¶å‘é€ node_start äº‹ä»¶
                        if node_from_tags not in seen_nodes:
                            seen_nodes.add(node_from_tags)
                            # å‘é€èŠ‚ç‚¹å¼€å§‹äº‹ä»¶ï¼ˆagent = æ€è€ƒä¸­ï¼Œexecution = æ‰§è¡Œå·¥å…·ï¼‰
                            display_name = "æ€è€ƒä¸­" if node_from_tags == "agent" else "æ‰§è¡Œå·¥å…·" if node_from_tags == "execution" else node_from_tags
                            yield f"data: {json.dumps({'type': 'node_start', 'node': node_from_tags, 'display': display_name}, ensure_ascii=False)}\n\n"

                    # 2. LLM tokenæµå¼è¾“å‡º â­ æ ¸å¿ƒåŠŸèƒ½
                    elif event_type == "on_chat_model_stream":
                        try:
                            # æå–èŠ‚ç‚¹åç§°
                            event_node = detect_node(event, fallback=current_node)

                            # âš ï¸ å…³é”®ä¿®æ”¹ï¼šè·³è¿‡ agent èŠ‚ç‚¹çš„æ‰€æœ‰æµå¼è¾“å‡ºï¼ˆé¿å…ä¸­é—´æ¨ç†è¿‡ç¨‹æ˜¾ç¤ºç»™ç”¨æˆ·ï¼‰
                            # agent èŠ‚ç‚¹çš„å†…å®¹ä¿ç•™åœ¨ state.messages ä¸­ä¾› LLM é˜…è¯»
                            # æœ€ç»ˆå“åº”ç”± response èŠ‚ç‚¹é€šè¿‡ on_chain_end äº‹ä»¶å‘é€ï¼ˆéæµå¼ï¼‰
                            if event_node == "agent":
                                # ä»ç„¶ç´¯åŠ åˆ° current_messageï¼ˆç”¨äºæ—¥å¿—å’Œè°ƒè¯•ï¼‰
                                chunk_data = event.get("data", {}).get("chunk", {})
                                if hasattr(chunk_data, "content"):
                                    token = chunk_data.content
                                elif isinstance(chunk_data, dict):
                                    token = chunk_data.get("content", "")
                                else:
                                    token = str(chunk_data) if chunk_data else ""
                                current_message += token if token else ""
                                continue  # è·³è¿‡å‘é€ç»™å‰ç«¯

                            chunk_data = event.get("data", {}).get("chunk", {})

                            # æå– token å†…å®¹
                            if hasattr(chunk_data, "content"):
                                token = chunk_data.content
                            elif isinstance(chunk_data, dict):
                                token = chunk_data.get("content", "")
                            else:
                                token = str(chunk_data) if chunk_data else ""

                            if not token:
                                continue

                            current_message += token

                            # å‘é€ token åˆ°å‰ç«¯
                            yield f"data: {json.dumps({'type': 'token', 'content': token, 'node': event_node}, ensure_ascii=False)}\n\n"

                        except Exception as token_error:
                            print(f"[Stream] Tokenå¤„ç†é”™è¯¯: {token_error}")

                    # 3. å·¥å…·è°ƒç”¨å¼€å§‹
                    elif event_type == "on_tool_start":
                        tool_name = event_name
                        yield f"data: {json.dumps({'type': 'tool_start', 'tool': tool_name}, ensure_ascii=False)}\n\n"

                    # 4. å·¥å…·è°ƒç”¨å®Œæˆ
                    elif event_type == "on_tool_end":
                        tool_name = event_name
                        tool_output = event.get("data", {}).get("output", "")

                        # é™åˆ¶å·¥å…·è¾“å‡ºé•¿åº¦
                        tool_result = str(tool_output)[:200] if tool_output else ""

                        yield f"data: {json.dumps({'type': 'tool_end', 'tool': tool_name, 'result': tool_result}, ensure_ascii=False)}\n\n"

                    # 5. èŠ‚ç‚¹å®Œæˆäº‹ä»¶
                    elif event_type == "on_chain_end" and node_from_tags:
                        if node_from_tags == current_node:
                            output_payload = event.get("data", {}).get("output")

                            # æ ‡è®°æ˜¯å¦æœ‰å†…å®¹è¾“å‡ºï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦å‘é€node_endï¼‰
                            has_content = bool(current_message.strip())

                            # âš ï¸ response èŠ‚ç‚¹è¾“å‡ºæœ€ç»ˆå“åº”ï¼ˆå› ä¸º agent èŠ‚ç‚¹çš„æµå¼è¾“å‡ºå·²è¢«è·³è¿‡ï¼‰
                            # execution èŠ‚ç‚¹ä¸åº”è¯¥æœ‰æ–‡æœ¬è¾“å‡º
                            if node_from_tags == "response":
                                sent_texts = node_sent_texts.setdefault(node_from_tags, set())
                                for text in _flatten_text(output_payload):
                                    cleaned = text.strip()
                                    if not cleaned:
                                        continue
                                    # è¿‡æ»¤èŠ‚ç‚¹åç§°å’Œå†…éƒ¨æ ‡è®°
                                    if cleaned in ["execution", "agent", "response", "terminate", "__end__", "__start__"]:
                                        continue
                                    if cleaned in sent_texts:
                                        continue
                                    sent_texts.add(cleaned)
                                    yield f"data: {json.dumps({'type': 'message', 'content': cleaned, 'node': node_from_tags}, ensure_ascii=False)}\n\n"
                                    has_content = True

                            # âœ… åªæœ‰å½“èŠ‚ç‚¹æœ‰å†…å®¹è¾“å‡ºæ—¶æ‰å‘é€node_endï¼ˆé¿å…ç©ºæ¶ˆæ¯ï¼‰
                            if has_content:
                                yield f"data: {json.dumps({'type': 'node_end', 'node': current_node}, ensure_ascii=False)}\n\n"

                            current_message = ""

                    # 6. Graph å®Œæˆäº‹ä»¶
                    elif event_type == "on_chain_end" and not node_from_tags and event_name == "LangGraph":
                        graph_finished = True
                        print(f"[Stream DEBUG] Graph execution finished")

                # âš ï¸ äº‹ä»¶å¾ªç¯ç»“æŸåï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ interrupt
                print(f"[Stream DEBUG] Event loop ended, checking for interrupt...")
                try:
                    state = await agent.aget_state(config)
                    print(f"[Stream DEBUG] Got state: next={state.next}, tasks={len(state.tasks) if state.tasks else 0}")

                    # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„ interrupt
                    if state.tasks:
                        for task in state.tasks:
                            if hasattr(task, 'interrupts') and task.interrupts:
                                for interrupt_item in task.interrupts:
                                    interrupt_value = interrupt_item.value if hasattr(interrupt_item, 'value') else interrupt_item
                                    print(f"[Stream] [HITL] æ£€æµ‹åˆ° interrupt: {interrupt_value}")

                                    # å‘é€ interrupt äº‹ä»¶ç»™å‰ç«¯
                                    yield f"data: {json.dumps({'type': 'interrupt', 'data': interrupt_value}, ensure_ascii=False)}\n\n"
                                    yield f"data: {json.dumps({'type': 'waiting_input', 'message': interrupt_value.get('message', 'è¯·ç¡®è®¤æ“ä½œ')}, ensure_ascii=False)}\n\n"

                                    # æ›´æ–°å¯¹è¯æ´»åŠ¨
                                    await update_conversation_activity(conversation_id, user_message)
                                    return  # åœæ­¢ï¼Œç­‰å¾…ç”¨æˆ· resume
                except Exception as state_error:
                    print(f"[Stream] è·å–çŠ¶æ€å¤±è´¥: {state_error}")

                # æ›´æ–°å¯¹è¯æ´»åŠ¨
                await update_conversation_activity(conversation_id, user_message)

                # âœ… è®°å½•è¯·æ±‚å®Œæˆ
                elapsed = time.time() - start_time
                logger.info(
                    "è¯·æ±‚å®Œæˆ",
                    endpoint="/chat/stream",
                    status="success",
                    duration_ms=int(elapsed * 1000)
                )

                # å‘é€å®Œæˆäº‹ä»¶ï¼ˆåŒ…å«æœ€åçš„èŠ‚ç‚¹ä¿¡æ¯ï¼‰
                yield f"data: {json.dumps({'type': 'done', 'message': 'å¤„ç†å®Œæˆ', 'node': current_node}, ensure_ascii=False)}\n\n"

            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()

                # âœ… è®°å½•é”™è¯¯
                logger.error(
                    "è¯·æ±‚å¤±è´¥",
                    endpoint="/chat/stream",
                    error=str(e),
                    error_type=type(e).__name__,
                    exc_info=True
                )
                yield f"data: {json.dumps({'type': 'error', 'message': str(e)}, ensure_ascii=False)}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        }
    )


@router.post("/chat/resume")
async def resume_chat(resume_request: ResumeRequest, request: Request):
    """æ¢å¤è¢«ä¸­æ–­çš„å¯¹è¯ï¼ˆHITLï¼‰

    å½“ Agent è§¦å‘ interrupt ç­‰å¾…ç”¨æˆ·è¾“å…¥æ—¶ï¼Œå‰ç«¯è°ƒç”¨æ­¤æ¥å£æ¢å¤æ‰§è¡Œã€‚

    Args:
        resume_request: æ¢å¤è¯·æ±‚ï¼ŒåŒ…å«ç”¨æˆ·å“åº”å€¼

    Returns:
        StreamingResponse: æµå¼è¿”å›åç»­æ‰§è¡Œç»“æœ
    """
    conversation_id = resume_request.conversation_id
    user_id = resume_request.user_id
    resume_value = resume_request.resume_value

    async def event_generator():
        """ç”Ÿæˆ SSE äº‹ä»¶"""
        try:
            # å‘é€æ¢å¤å¼€å§‹äº‹ä»¶
            yield f"data: {json.dumps({'type': 'resume_start', 'message': 'æ­£åœ¨æ¢å¤æ‰§è¡Œ...'}, ensure_ascii=False)}\n\n"

            # ä» app.state è·å–Agent
            agent = request.app.state.agent

            # âœ… åˆ›å»ºç‹¬ç«‹çš„ LangFuse handlerï¼ˆv3.x å®˜æ–¹æ–¹å¼ï¼‰
            langfuse_handler, langfuse_metadata = create_langfuse_handler(
                session_id=conversation_id,
                user_id=user_id,
                tags=["production", "navigation", "resume"],
                metadata={
                    "is_resume": True
                }
            )

            # é…ç½® Checkpointing å’Œ LangFuse
            config = {
                "configurable": {
                    "thread_id": conversation_id,
                    "user_id": user_id
                }
            }

            # âœ… v3.x: é€šè¿‡ metadata ä¼ é€’ session_id å’Œ user_id
            if langfuse_handler and langfuse_metadata:
                config["callbacks"] = [langfuse_handler]
                config["metadata"] = langfuse_metadata

            # çŠ¶æ€è·Ÿè¸ª
            current_node = None
            current_message = ""
            seen_nodes = set()
            node_sent_texts: Dict[str, Set[str]] = {}

            def detect_node(event, fallback=None):
                """æ ¹æ®äº‹ä»¶å…ƒæ•°æ®æå–å½“å‰èŠ‚ç‚¹åç§°"""
                metadata = event.get("metadata", {}) or {}
                tags = event.get("tags", []) or []

                node_name = metadata.get("langgraph_node") or metadata.get("node")
                if node_name:
                    return node_name

                for tag in tags:
                    if tag.startswith("langgraph_node:"):
                        return tag.split(":", 1)[1]

                return fallback

            # ä½¿ç”¨ Command(resume=...) æ¢å¤æ‰§è¡Œ
            start_time = time.time()
            async for event in agent.astream_events(
                Command(resume=resume_value),
                config,
                version="v2"
            ):
                # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
                elapsed = time.time() - start_time
                if elapsed > 120:  # 2åˆ†é’Ÿ
                    print(f"[Resume] Agentæ‰§è¡Œè¶…æ—¶ï¼")
                    yield f"data: {json.dumps({'type': 'error', 'message': 'ä»»åŠ¡æ‰§è¡Œè¶…æ—¶'}, ensure_ascii=False)}\n\n"
                    break

                event_type = event["event"]
                event_name = event.get("name", "")

                # ä»äº‹ä»¶ä¸­è§£æèŠ‚ç‚¹åç§°
                node_from_tags = detect_node(event)

                # 1. èŠ‚ç‚¹å¼€å§‹äº‹ä»¶
                if event_type == "on_chain_start" and node_from_tags:
                    current_node = node_from_tags
                    current_message = ""

                    if node_from_tags not in seen_nodes:
                        seen_nodes.add(node_from_tags)
                        display_name = "æ€è€ƒä¸­" if node_from_tags == "agent" else "æ‰§è¡Œå·¥å…·" if node_from_tags == "execution" else node_from_tags
                        yield f"data: {json.dumps({'type': 'node_start', 'node': node_from_tags, 'display': display_name}, ensure_ascii=False)}\n\n"

                # 2. LLM tokenæµå¼è¾“å‡º
                elif event_type == "on_chat_model_stream":
                    try:
                        event_node = detect_node(event, fallback=current_node)

                        # âš ï¸ å…³é”®ä¿®æ”¹ï¼šè·³è¿‡ agent èŠ‚ç‚¹çš„æ‰€æœ‰æµå¼è¾“å‡ºï¼ˆé¿å…ä¸­é—´æ¨ç†è¿‡ç¨‹æ˜¾ç¤ºç»™ç”¨æˆ·ï¼‰
                        # ä¸ /chat/stream ä¿æŒä¸€è‡´çš„é€»è¾‘
                        if event_node == "agent":
                            chunk_data = event.get("data", {}).get("chunk", {})
                            if hasattr(chunk_data, "content"):
                                token = chunk_data.content
                            elif isinstance(chunk_data, dict):
                                token = chunk_data.get("content", "")
                            else:
                                token = str(chunk_data) if chunk_data else ""
                            current_message += token if token else ""
                            continue  # è·³è¿‡å‘é€ç»™å‰ç«¯

                        chunk_data = event.get("data", {}).get("chunk", {})

                        if hasattr(chunk_data, "content"):
                            token = chunk_data.content
                        elif isinstance(chunk_data, dict):
                            token = chunk_data.get("content", "")
                        else:
                            token = str(chunk_data) if chunk_data else ""

                        if not token:
                            continue

                        current_message += token
                        yield f"data: {json.dumps({'type': 'token', 'content': token, 'node': event_node or 'agent'}, ensure_ascii=False)}\n\n"

                    except Exception as token_error:
                        print(f"[Resume] Tokenå¤„ç†é”™è¯¯: {token_error}")

                # 3. å·¥å…·è°ƒç”¨å¼€å§‹
                elif event_type == "on_tool_start":
                    tool_name = event_name
                    yield f"data: {json.dumps({'type': 'tool_start', 'tool': tool_name}, ensure_ascii=False)}\n\n"

                # 4. å·¥å…·è°ƒç”¨å®Œæˆ
                elif event_type == "on_tool_end":
                    tool_name = event_name
                    tool_output = event.get("data", {}).get("output", "")
                    tool_result = str(tool_output)[:200] if tool_output else ""
                    yield f"data: {json.dumps({'type': 'tool_end', 'tool': tool_name, 'result': tool_result}, ensure_ascii=False)}\n\n"

                # 5. èŠ‚ç‚¹å®Œæˆäº‹ä»¶
                elif event_type == "on_chain_end" and node_from_tags:
                    if node_from_tags == current_node:
                        output_payload = event.get("data", {}).get("output")
                        has_content = bool(current_message.strip())

                        # âš ï¸ response èŠ‚ç‚¹è¾“å‡ºæœ€ç»ˆå“åº”ï¼ˆReAct æ¶æ„è®¾è®¡ï¼‰
                        # agent = æ€è€ƒè¿‡ç¨‹ï¼ˆé»‘ç›’ï¼Œä¸è¾“å‡ºï¼‰
                        # execution = å·¥å…·æ‰§è¡Œï¼ˆå†…éƒ¨è¿‡ç¨‹ï¼Œä¸è¾“å‡ºï¼‰
                        # response = æœ€ç»ˆå“åº”ï¼ˆç™½ç›’ï¼Œç”¨æˆ·å¯è§ï¼‰
                        if node_from_tags == "response":
                            sent_texts = node_sent_texts.setdefault(node_from_tags, set())
                            for text in _flatten_text(output_payload):
                                cleaned = text.strip()
                                if not cleaned:
                                    continue
                                # è¿‡æ»¤èŠ‚ç‚¹åç§°å’Œå†…éƒ¨æ ‡è®°
                                if cleaned in ["execution", "agent", "response", "terminate", "__end__", "__start__"]:
                                    continue
                                if cleaned in sent_texts:
                                    continue
                                sent_texts.add(cleaned)
                                yield f"data: {json.dumps({'type': 'message', 'content': cleaned, 'node': node_from_tags}, ensure_ascii=False)}\n\n"
                                has_content = True

                        # âœ… åªæœ‰å½“èŠ‚ç‚¹æœ‰å†…å®¹è¾“å‡ºæ—¶æ‰å‘é€node_endï¼ˆé¿å…ç©ºæ¶ˆæ¯ï¼‰
                        if has_content:
                            yield f"data: {json.dumps({'type': 'node_end', 'node': current_node}, ensure_ascii=False)}\n\n"

                        # é‡ç½®å½“å‰æ¶ˆæ¯ç´¯ç§¯
                        current_message = ""

            # âš ï¸ äº‹ä»¶å¾ªç¯ç»“æŸåï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ interruptï¼ˆä¸ /chat/stream ç›¸åŒçš„é€»è¾‘ï¼‰
            print(f"[Resume DEBUG] Event loop ended, checking for interrupt...")
            try:
                state = await agent.aget_state(config)
                print(f"[Resume DEBUG] Got state: next={state.next}, tasks={len(state.tasks) if state.tasks else 0}")

                # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„ interrupt
                if state.tasks:
                    for task in state.tasks:
                        if hasattr(task, 'interrupts') and task.interrupts:
                            for interrupt_item in task.interrupts:
                                interrupt_value = interrupt_item.value if hasattr(interrupt_item, 'value') else interrupt_item
                                print(f"[Resume] [HITL] æ£€æµ‹åˆ° interrupt: {interrupt_value}")

                                # å‘é€ interrupt äº‹ä»¶ç»™å‰ç«¯
                                yield f"data: {json.dumps({'type': 'interrupt', 'data': interrupt_value}, ensure_ascii=False)}\n\n"
                                yield f"data: {json.dumps({'type': 'waiting_input', 'message': interrupt_value.get('message', 'è¯·ç¡®è®¤æ“ä½œ')}, ensure_ascii=False)}\n\n"
                                return  # åœæ­¢ï¼Œç­‰å¾…ç”¨æˆ· resume
            except Exception as state_error:
                print(f"[Resume] è·å–çŠ¶æ€å¤±è´¥: {state_error}")

            # å‘é€å®Œæˆäº‹ä»¶
            yield f"data: {json.dumps({'type': 'done', 'message': 'æ¢å¤æ‰§è¡Œå®Œæˆ', 'node': current_node}, ensure_ascii=False)}\n\n"

        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            print(f"[Resume] é”™è¯¯: {error_detail}")
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)}, ensure_ascii=False)}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        }
    )


@router.get("/mcp/status")
async def get_mcp_status(request: Request):
    """
    è·å– MCP è¿æ¥çŠ¶æ€

    Returns:
        å„ MCP æœåŠ¡çš„è¿æ¥çŠ¶æ€
    """
    from ..mcp.manager import mcp_manager

    status = mcp_manager.get_sse_connection_status()

    return {
        "status": "ok",
        "connections": status
    }


@router.post("/mcp/reconnect")
async def reconnect_mcp(request: Request, server_name: Optional[str] = None):
    """
    æ‰‹åŠ¨é‡è¿ MCP æœåŠ¡

    Args:
        server_name: æŒ‡å®šé‡è¿çš„æœåŠ¡åç§°ï¼Œä¸ä¼ åˆ™é‡è¿æ‰€æœ‰æ–­å¼€çš„æœåŠ¡

    Returns:
        é‡è¿ç»“æœ
    """
    from ..mcp.manager import mcp_manager

    results = mcp_manager.reconnect_sse(server_name)

    return {
        "status": "ok",
        "reconnect_results": results
    }


@router.get("/memory/check-profile")
async def check_profile_status(user_id: str = "user_001"):
    """
    æ£€æŸ¥ç”¨æˆ· profile æ˜¯å¦å·²åˆå§‹åŒ–

    ç”¨äºå‰ç«¯åˆ¤æ–­æ˜¯å¦éœ€è¦æ˜¾ç¤ºå¼•å¯¼æ¶ˆæ¯ã€‚

    Args:
        user_id: ç”¨æˆ·IDï¼ˆé»˜è®¤ user_001ï¼‰

    Returns:
        {
            "user_id": str,
            "is_initialized": bool,
            "greeting": str | null  # å¦‚æœæœªåˆå§‹åŒ–ï¼Œè¿”å›å¼•å¯¼æ¶ˆæ¯
        }
    """
    from ..memory.service import MemoryService

    memory_service = MemoryService(db_path="data/memory.db")
    is_initialized = memory_service.check_profile_initialized(user_id)

    greeting = None
    if not is_initialized:
        greeting = "ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„æ™ºèƒ½è½¦è½½åŠ©æ‰‹ã€‚ä¸ºäº†æ›´å¥½åœ°ä¸ºä½ æœåŠ¡ï¼Œèƒ½ç®€å•ä»‹ç»ä¸‹è‡ªå·±å—ï¼Ÿæ¯”å¦‚ä½ çš„èŒä¸šã€å…´è¶£çˆ±å¥½ç­‰~ï¼ˆä¹Ÿå¯ä»¥ç›´æ¥å‘Šè¯‰æˆ‘éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼‰"

    return {
        "user_id": user_id,
        "is_initialized": is_initialized,
        "greeting": greeting
    }

