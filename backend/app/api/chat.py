"""Chat API æ¥å£"""
from fastapi import APIRouter, Request, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from typing import List, Optional, Any, Iterable, Dict, Set
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
import json
import asyncio
import time

# Agentä»app.stateä¸­è·å–ï¼Œä¸éœ€è¦å¯¼å…¥
from ..config import config

router = APIRouter()


class ImageData(BaseModel):
    """å›¾ç‰‡æ•°æ®"""
    type: str = Field(default="base64", description="å›¾ç‰‡ç±»å‹: base64 æˆ– url")
    data: str = Field(..., description="Base64ç¼–ç çš„å›¾ç‰‡æ•°æ®æˆ–URL")


class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚"""
    message: str
    thread_id: str = "default"
    user_id: str = "default"  # âœ… æ–°å¢ï¼šç”¨æˆ·IDï¼Œç”¨äºMem0é•¿æœŸè®°å¿†
    images: Optional[List[ImageData]] = Field(default=None, description="å›¾ç‰‡åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰")


class ChatResponse(BaseModel):
    """èŠå¤©å“åº”"""
    response: str
    thread_id: str


def build_message(text: str, images: Optional[List[ImageData]] = None) -> HumanMessage:
    """
    æ„å»º LangChain æ¶ˆæ¯ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰

    Args:
        text: æ–‡æœ¬å†…å®¹
        images: å›¾ç‰‡åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰

    Returns:
        HumanMessage: LangChain æ¶ˆæ¯å¯¹è±¡
    """
    if not images or len(images) == 0:
        # çº¯æ–‡æœ¬æ¶ˆæ¯
        return HumanMessage(content=text)

    # å¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆå›¾ç‰‡ + æ–‡æœ¬ï¼‰
    content = []

    # æ·»åŠ æ–‡æœ¬éƒ¨åˆ†
    if text and text.strip():
        content.append({
            "type": "text",
            "text": text
        })

    # æ·»åŠ å›¾ç‰‡éƒ¨åˆ†
    for img in images:
        if img.type == "base64":
            # Base64æ ¼å¼
            # ç¡®ä¿dataåŒ…å«å®Œæ•´çš„data URIæ ¼å¼
            image_data = img.data
            if not image_data.startswith("data:"):
                # å¦‚æœæ²¡æœ‰data URIå‰ç¼€ï¼Œæ·»åŠ é»˜è®¤çš„
                image_data = f"data:image/jpeg;base64,{image_data}"

            content.append({
                "type": "image_url",
                "image_url": {
                    "url": image_data
                }
            })
        elif img.type == "url":
            # URLæ ¼å¼
            content.append({
                "type": "image_url",
                "image_url": {
                    "url": img.data
                }
            })

    return HumanMessage(content=content)


def _flatten_text(value: Any) -> Iterable[str]:
    """ä»å¤šç§è¿”å›ç»“æ„ä¸­æå–çº¯æ–‡æœ¬ï¼Œå…¼å®¹ LangChain/BaseMessageã€dictã€list.

    æ³¨æ„ï¼šä¼šè‡ªåŠ¨è¿‡æ»¤ToolMessageï¼ˆå·¥å…·çš„åŸå§‹è¿”å›ï¼‰ï¼Œåªæå–AIMessageçš„ï¿½ï¿½ï¿½å®¹
    """
    if value is None:
        return []

    # âœ… LangChain Message å¯¹è±¡ - è·³è¿‡ToolMessage
    if isinstance(value, ToolMessage):
        return []  # ä¸æ˜¾ç¤ºå·¥å…·çš„åŸå§‹è¿”å›

    content = getattr(value, "content", None)
    if content is not None:
        if isinstance(content, str):
            return [content]
        if isinstance(content, list):
            texts: List[str] = []
            for item in content:
                texts.extend(_flatten_text(item))
            return texts
        return [str(content)]

    if isinstance(value, str):
        return [value]

    if isinstance(value, list):
        texts: List[str] = []
        for item in value:
            texts.extend(_flatten_text(item))
        return texts

    if isinstance(value, dict):
        # LangGraph èŠ‚ç‚¹è¾“å‡ºé€šå¸¸åŒ…å« messages / output ç­‰å­—æ®µ
        if "messages" in value:
            texts: List[str] = []
            for item in value["messages"]:
                # âœ… è¿‡æ»¤ToolMessage
                if not isinstance(item, ToolMessage):
                    texts.extend(_flatten_text(item))
            return texts
        if "output" in value:
            return list(_flatten_text(value["output"]))
        if "content" in value:
            return list(_flatten_text(value["content"]))
        # éå†å…¶å®ƒå­—æ®µ
        texts: List[str] = []
        for item in value.values():
            texts.extend(_flatten_text(item))
        return texts

    return [str(value)]


@router.post("/chat", response_model=ChatResponse)
async def chat(chat_request: ChatRequest, request: Request):
    """æ ‡å‡† Chat æ¥å£ï¼ˆéæµå¼ï¼‰"""

    # ä» app.state è·å–Agent
    agent = request.app.state.agent

    # é…ç½® Checkpointingï¼ˆä½¿ç”¨ thread_idï¼‰
    config = {"configurable": {"thread_id": chat_request.thread_id}}

    # æ„é€ åˆå§‹çŠ¶æ€ï¼ˆåŒ…å«æ¶ˆæ¯å’Œè®¡æ•°å™¨ï¼‰
    initial_state = {
        "messages": [build_message(chat_request.message, chat_request.images)],
        "iteration_count": 0,      # åˆå§‹åŒ–å¾ªç¯è®¡æ•°å™¨
        "total_tool_calls": 0,     # åˆå§‹åŒ–å·¥å…·è°ƒç”¨è®¡æ•°å™¨
    }

    # è¿è¡Œ Agent
    final_state = await agent.app.ainvoke(initial_state, config)

    # æå–æœ€ç»ˆå“åº”ï¼ˆåªä¿ç•™AIæ¶ˆæ¯ï¼‰
    response_messages = []
    for msg in final_state["messages"]:
        # åªæå–AIçš„å›å¤
        if isinstance(msg, AIMessage):
            content = msg.content

            # å¤„ç†å¤šæ¨¡æ€æ¶ˆæ¯ï¼ˆcontentå¯èƒ½æ˜¯åˆ—è¡¨ï¼‰
            if isinstance(content, str):
                if content.strip():  # è·³è¿‡ç©ºå†…å®¹
                    response_messages.append(content)
            elif isinstance(content, list):
                # å¤šæ¨¡æ€æ¶ˆæ¯ï¼Œæå–æ–‡æœ¬éƒ¨åˆ†
                text_parts = [item.get("text", "") for item in content if isinstance(item, dict) and item.get("type") == "text"]
                if text_parts:
                    response_messages.append(" ".join(text_parts))
            else:
                response_messages.append(str(content))

    # åªè¿”å›æœ€åä¸€æ¡AIå›å¤
    final_response = response_messages[-1] if response_messages else "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç”Ÿæˆå›å¤ã€‚"

    return ChatResponse(
        response=final_response,
        thread_id=chat_request.thread_id
    )


@router.post("/chat/stream")
async def chat_stream(chat_request: ChatRequest, request: Request):
    """SSE æµå¼ Chat æ¥å£ - çœŸæ­£çš„LLMæµå¼è¾“å‡º"""

    user_message = chat_request.message
    thread_id = chat_request.thread_id
    user_id = chat_request.user_id  # âœ… è·å–user_id

    async def event_generator():
        """ç”Ÿæˆ SSE äº‹ä»¶"""
        try:
            # å‘é€å¼€å§‹äº‹ä»¶
            yield f"data: {json.dumps({'type': 'start', 'message': 'å¼€å§‹å¤„ç†...'}, ensure_ascii=False)}\n\n"

            # ä» app.state è·å–Agent
            agent = request.app.state.agent

            # é…ç½® Checkpointingï¼ˆä½¿ç”¨ thread_id å’Œ user_idï¼‰
            config = {"configurable": {"thread_id": thread_id, "user_id": user_id}}

            # æ„é€ åˆå§‹çŠ¶æ€ï¼ˆåŒ…å«æ¶ˆæ¯å’Œè®¡æ•°å™¨ï¼‰
            initial_state = {
                "messages": [build_message(user_message, chat_request.images)],
                "iteration_count": 0,      # åˆå§‹åŒ–å¾ªç¯è®¡æ•°å™¨
                "total_tool_calls": 0,     # åˆå§‹åŒ–å·¥å…·è°ƒç”¨è®¡æ•°å™¨
            }

            # çŠ¶æ€è·Ÿè¸ª
            current_node = None
            current_message = ""
            seen_nodes = set()  # ç”¨äºèŠ‚ç‚¹äº‹ä»¶å»é‡ï¼ˆä»…ç”¨äºnode_startæ¶ˆæ¯ï¼‰
            node_sent_texts: Dict[str, Set[str]] = {}

            def detect_node(event, fallback=None):
                """æ ¹æ®äº‹ä»¶å…ƒæ•°æ®æå–å½“å‰èŠ‚ç‚¹åç§°"""
                metadata = event.get("metadata", {}) or {}
                tags = event.get("tags", []) or []

                node_name = metadata.get("langgraph_node") or metadata.get("node")
                if node_name:
                    return node_name

                for tag in tags:
                    if tag.startswith("langgraph_node:"):
                        return tag.split(":", 1)[1]

                return fallback

            # âœ… ä½¿ç”¨ Agent çš„ astream_events è·å–çœŸæ­£çš„æµå¼è¾“å‡º
            # âœ… æ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼ˆ2åˆ†é’Ÿï¼‰
            start_time = time.time()
            async for event in agent.astream_events(initial_state, config):
                # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
                elapsed = time.time() - start_time
                if elapsed > 120:  # 2åˆ†é’Ÿ
                    print(f"\n{'='*60}")
                    print(f"[Stream] âš ï¸ Agentæ‰§è¡Œè¶…æ—¶ï¼")
                    print(f"[Stream] ğŸ“Š å·²æ‰§è¡Œæ—¶é—´: {elapsed:.2f} ç§’")
                    print(f"[Stream] ğŸ“Š è¶…æ—¶é™åˆ¶: 120 ç§’ï¼ˆ2åˆ†é’Ÿï¼‰")
                    print(f"[Stream] ğŸš« å¼ºåˆ¶ç»ˆæ­¢æ‰§è¡Œ")
                    print(f"{'='*60}\n")
                    yield f"data: {json.dumps({'type': 'error', 'message': 'ä»»åŠ¡æ‰§è¡Œè¶…æ—¶ï¼ˆ2åˆ†é’Ÿï¼‰ï¼Œå·²å¼ºåˆ¶ç»ˆæ­¢'}, ensure_ascii=False)}\n\n"
                    break

                event_type = event["event"]
                event_name = event.get("name", "")

                # ä»äº‹ä»¶ä¸­è§£æèŠ‚ç‚¹åç§°
                node_from_tags = detect_node(event)

                # 1. èŠ‚ç‚¹å¼€å§‹äº‹ä»¶
                if event_type == "on_chain_start" and node_from_tags:
                    # æ›´æ–° current_node
                    current_node = node_from_tags
                    current_message = ""

                    # åªåœ¨ç¬¬ä¸€æ¬¡è¿›å…¥æ—¶å‘é€ node_start äº‹ä»¶
                    if node_from_tags not in seen_nodes:
                        seen_nodes.add(node_from_tags)
                        # å‘é€èŠ‚ç‚¹å¼€å§‹äº‹ä»¶ï¼ˆreasoning = æ€è€ƒä¸­ï¼Œaction = æ‰§è¡Œå·¥å…·ï¼‰
                        display_name = "æ€è€ƒä¸­" if node_from_tags == "reasoning" else "æ‰§è¡Œå·¥å…·" if node_from_tags == "action" else node_from_tags
                        yield f"data: {json.dumps({'type': 'node_start', 'node': node_from_tags, 'display': display_name}, ensure_ascii=False)}\n\n"

                # 2. LLM tokenæµå¼è¾“å‡º â­ æ ¸å¿ƒåŠŸèƒ½
                elif event_type == "on_chat_model_stream":
                    try:
                        # æå–èŠ‚ç‚¹åç§°
                        event_node = detect_node(event, fallback=current_node)

                        chunk_data = event.get("data", {}).get("chunk", {})

                        # æå– token å†…å®¹
                        if hasattr(chunk_data, "content"):
                            token = chunk_data.content
                        elif isinstance(chunk_data, dict):
                            token = chunk_data.get("content", "")
                        else:
                            token = str(chunk_data) if chunk_data else ""

                        if not token:
                            continue

                        current_message += token

                        # å‘é€ token åˆ°å‰ç«¯
                        yield f"data: {json.dumps({'type': 'token', 'content': token, 'node': event_node or 'reasoning'}, ensure_ascii=False)}\n\n"

                    except Exception as token_error:
                        print(f"[Stream] Tokenå¤„ç†é”™è¯¯: {token_error}")

                # 3. å·¥å…·è°ƒç”¨å¼€å§‹
                elif event_type == "on_tool_start":
                    tool_name = event_name
                    yield f"data: {json.dumps({'type': 'tool_start', 'tool': tool_name}, ensure_ascii=False)}\n\n"

                # 4. å·¥å…·è°ƒç”¨å®Œæˆ
                elif event_type == "on_tool_end":
                    tool_name = event_name
                    tool_output = event.get("data", {}).get("output", "")

                    # é™åˆ¶å·¥å…·è¾“å‡ºé•¿åº¦
                    tool_result = str(tool_output)[:200] if tool_output else ""

                    yield f"data: {json.dumps({'type': 'tool_end', 'tool': tool_name, 'result': tool_result}, ensure_ascii=False)}\n\n"

                # 5. èŠ‚ç‚¹å®Œæˆäº‹ä»¶
                elif event_type == "on_chain_end" and node_from_tags:
                    if node_from_tags == current_node:
                        output_payload = event.get("data", {}).get("output")

                        # æ ‡è®°æ˜¯å¦æœ‰å†…å®¹è¾“å‡ºï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦å‘é€node_endï¼‰
                        has_content = bool(current_message.strip())

                        # å¦‚æœæ²¡æœ‰å®æ—¶tokenè¾“å‡ºï¼Œå°è¯•ä»èŠ‚ç‚¹è¾“å‡ºä¸­æå–æ–‡æœ¬ä¸€æ¬¡æ€§å‘é€
                        if not current_message.strip():
                            sent_texts = node_sent_texts.setdefault(node_from_tags, set())
                            for text in _flatten_text(output_payload):
                                cleaned = text.strip()
                                if not cleaned:
                                    continue
                                if cleaned in sent_texts:
                                    continue
                                sent_texts.add(cleaned)
                                yield f"data: {json.dumps({'type': 'message', 'content': cleaned, 'node': node_from_tags}, ensure_ascii=False)}\n\n"
                                has_content = True  # æ ‡è®°å·²å‘é€å†…å®¹

                        # âœ… åªæœ‰å½“èŠ‚ç‚¹æœ‰å†…å®¹è¾“å‡ºæ—¶æ‰å‘é€node_endï¼ˆé¿å…actionèŠ‚ç‚¹äº§ç”Ÿç©ºæ¶ˆæ¯ï¼‰
                        if has_content:
                            yield f"data: {json.dumps({'type': 'node_end', 'node': current_node}, ensure_ascii=False)}\n\n"

                        current_message = ""

            # å‘é€å®Œæˆäº‹ä»¶ï¼ˆåŒ…å«æœ€åçš„èŠ‚ç‚¹ä¿¡æ¯ï¼‰
            yield f"data: {json.dumps({'type': 'done', 'message': 'å¤„ç†å®Œæˆ', 'node': current_node}, ensure_ascii=False)}\n\n"

        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            print(f"[Stream] é”™è¯¯: {error_detail}")
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)}, ensure_ascii=False)}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        }
    )
