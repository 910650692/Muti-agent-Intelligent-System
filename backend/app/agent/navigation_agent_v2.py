"""
Navigation Agent V2 - ç®€åŒ–ç‰ˆReActæ¶æ„

è®¾è®¡ç›®æ ‡ï¼š
1. æ¸…æ™°çš„èŒè´£åˆ†ç¦»ï¼šAgentæ¨ç† â†’ Executionæ‰§è¡Œ â†’ Responseå“åº”
2. æ ‡å‡†åŒ–è¾“å‡ºæ ¼å¼ï¼šdecision JSON
3. æ”¯æŒä¸‰ç§åœºæ™¯ï¼šçº¯å¯¹è¯ã€å¯¹è¯ä»»åŠ¡ã€ä¸»åŠ¨æœåŠ¡
4. æ˜“äºæµ‹è¯•å’Œæ‰©å±•
"""
import json
from typing import List, Dict, Any, Optional
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, END
from langgraph.types import interrupt, Command

from ..state.agent_state import AgentState
from ..llm import get_llm
from ..mcp.manager import mcp_manager
from ..tools.weather_tools import weather_tools
from ..memory.memory_tools import memory_tools
from ..utils.structured_logger import get_logger
from .hitl_config import (
    need_confirmation,
    need_selection,
    get_missing_param_prompt,
    get_confirmation_message,
    get_selection_message,
    is_candidate_list
)
from .prompts import CONSTITUTION, MEMORY_GUIDE

logger = get_logger(__name__)


class AgentConfig:
    """Agentè¿è¡Œé…ç½®"""
    MAX_ITERATIONS = 10           # æœ€å¤§å¾ªç¯æ¬¡æ•°
    MAX_TOTAL_TOOL_CALLS = 50     # å…¨å±€æœ€å¤šå·¥å…·è°ƒç”¨æ¬¡æ•°ï¼ˆæ¯”V1æ›´ä¿å®ˆï¼‰


class NavigationAgentV2:
    """å¯¼èˆªAgent V2 - ç®€åŒ–ç‰ˆ"""

    def __init__(self):
        self.llm = get_llm(force_text=True)

        # åŠ è½½æ‰€æœ‰å·¥å…·
        self.tools = []

        # 1. åŠ è½½MCPå·¥å…·ï¼ˆå¯¼èˆªç›¸å…³ï¼‰
        mcp_tools = mcp_manager.load_all_tools()
        self.tools.extend(mcp_tools)
        logger.info(f"MCPå·¥å…·åŠ è½½å®Œæˆ: {len(mcp_tools)} ä¸ª")

        # 2. åŠ è½½å¤©æ°”å·¥å…·ï¼ˆfunction callï¼‰
        self.tools.extend(weather_tools)
        logger.info(f"å¤©æ°”å·¥å…·åŠ è½½å®Œæˆ: {len(weather_tools)} ä¸ª")

        # 3. åŠ è½½è®°å¿†å·¥å…·ï¼ˆPhase 1: ä½ç½®+åå¥½è®°å¿†ï¼‰
        # âš ï¸ è¿‡æ»¤æ‰ä¿å­˜å·¥å…·ï¼ˆè¿™äº›å·¥å…·ç”±ç³»ç»Ÿè‡ªåŠ¨è°ƒç”¨ï¼ŒAgentä¸åº”ç›´æ¥ä½¿ç”¨ï¼‰
        excluded_tools = {"memory_save_user_profile", "memory_save_relationship"}
        filtered_memory_tools = [
            tool for tool in memory_tools
            if tool.name not in excluded_tools
        ]
        self.tools.extend(filtered_memory_tools)
        logger.info(f"è®°å¿†å·¥å…·åŠ è½½å®Œæˆ: {len(filtered_memory_tools)} ä¸ªï¼ˆå·²è¿‡æ»¤ {len(memory_tools) - len(filtered_memory_tools)} ä¸ªä¿å­˜å·¥å…·ï¼‰")

        # 4. ä¿å­˜å®Œæ•´çš„å·¥å…·åˆ—è¡¨ï¼ˆåŒ…å«ä¿å­˜å·¥å…·ï¼Œä¾›executionèŠ‚ç‚¹ä½¿ç”¨ï¼‰
        self._all_memory_tools = memory_tools

        logger.info(f"Agent V2 åˆå§‹åŒ–å®Œæˆï¼Œæ€»è®¡åŠ è½½ {len(self.tools)} ä¸ªå·¥å…·")

    # ==================== Node 1: Agent æ¨ç† ====================

    async def agent_node(self, state: AgentState, config: RunnableConfig = None) -> Dict:
        """
        Agentæ¨ç†èŠ‚ç‚¹ï¼šç†è§£æ„å›¾ï¼Œå†³ç­–å·¥å…·è°ƒç”¨

        è¾“å…¥ï¼š
        - messages: å¯¹è¯å†å²
        - action_results: ä¸Šä¸€è½®å·¥å…·æ‰§è¡Œç»“æœï¼ˆObservationï¼‰

        è¾“å‡ºï¼š
        - decision: {
            "think": "æ¨ç†è¿‡ç¨‹",
            "actions": [{"name": "å·¥å…·å", "args": {...}}],
            "response": "ç»™ç”¨æˆ·çš„å›å¤",
            "is_complete": bool
          }
        """
        messages = state["messages"]
        iteration = state.get("iteration_count", 0) + 1
        action_results = state.get("action_results", [])

        # ğŸ“‹ è®°å½•æœ€æ–°æ¶ˆæ¯ï¼ˆå¯èƒ½æ˜¯ç”¨æˆ·è¾“å…¥æˆ–ä¸Šä¸€è½®çš„ AI å›å¤ï¼‰
        if messages:
            last_message = messages[-1]
            if hasattr(last_message, 'content'):
                msg_type = type(last_message).__name__
                emoji = "ğŸ“¥" if msg_type == "HumanMessage" else "ğŸ¤–"
                logger.info(
                    f"{emoji} æœ€æ–°æ¶ˆæ¯",
                    iteration=iteration,
                    content=last_message.content,
                    message_type=msg_type
                )

        # ğŸ“¸ Messages å¿«ç…§ï¼ˆè°ƒè¯•ç”¨ï¼‰
        logger.debug(
            "ğŸ“¸ Messages å¿«ç…§",
            iteration=iteration,
            messages=[
                {
                    "type": type(msg).__name__,
                    "content": msg.content[:100] if hasattr(msg, 'content') and msg.content else "",
                    "has_tool_calls": hasattr(msg, 'tool_calls') and bool(msg.tool_calls)
                }
                for msg in messages
            ]
        )

        logger.info(
            "Agentæ¨ç†å¼€å§‹",
            iteration=iteration,
            message_count=len(messages),
            has_previous_results=bool(action_results)
        )

        # ä»configä¸­è·å–user_id
        user_id = "default_user"  # é»˜è®¤å€¼
        if config and "configurable" in config:
            user_id = config["configurable"].get("user_id", "default_user")

        # æ„å»ºSystem Prompt
        system_prompt = self._build_system_prompt(iteration, action_results, user_id)

        # æ„å»ºå®Œæ•´æ¶ˆæ¯
        full_messages = [
            SystemMessage(content=system_prompt),
            *messages
        ]

        # è°ƒç”¨LLMï¼ˆç»‘å®šå·¥å…·ï¼‰
        model_with_tools = self.llm.bind_tools(self.tools)

        try:
            response = await model_with_tools.ainvoke(full_messages, config=config)
        except Exception as e:
            logger.error("LLMè°ƒç”¨å¤±è´¥", error=str(e))
            return {
                "decision": {
                    "think": f"LLMè°ƒç”¨å¤±è´¥: {e}",
                    "actions": [],
                    "response": "æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‡ºé”™äº†",
                    "is_complete": True
                },
                "messages": [AIMessage(content="æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‡ºé”™äº†")],
                "iteration_count": iteration
            }

        # è§£æLLMè¾“å‡º
        content = response.content or ""
        tool_calls = getattr(response, "tool_calls", [])

        # ğŸ“¤ è®°å½• LLM åŸå§‹è¾“å‡º
        logger.info(
            "ğŸ“¤ LLM åŸå§‹è¾“å‡º",
            iteration=iteration,
            content=content,
            tool_calls_count=len(tool_calls) if tool_calls else 0,
            has_tool_calls=bool(tool_calls)
        )

        # æ„å»ºdecision
        decision = self._build_decision(content, tool_calls, iteration, action_results)

        # ğŸ“Š è®°å½• Decision è¯¦æƒ…
        logger.info(
            "ğŸ“Š Decision è¯¦æƒ…",
            iteration=iteration,
            think=decision.get("think", ""),
            response=decision.get("response", ""),
            actions=decision.get("actions", []),
            is_complete=decision.get("is_complete", False)
        )

        logger.info(
            "Agentæ¨ç†å®Œæˆ",
            has_tools=bool(decision["actions"]),
            tool_count=len(decision["actions"]),
            is_complete=decision["is_complete"]
        )

        return {
            "decision": decision,
            # âœ… ä¿ç•™å®Œæ•´çš„ AIMessageï¼ˆåŒ…å« contentï¼‰ï¼Œä¾› LLM åœ¨ä¸‹ä¸€è½®è¿­ä»£æ—¶é˜…è¯»
            # å‰ç«¯è¿‡æ»¤ç”± chat.py çš„æµå¼è¾“å‡ºé€»è¾‘æ§åˆ¶
            "messages": [response],  # åŒ…å« content å’Œ tool_calls
            "iteration_count": iteration
        }

    def _build_system_prompt(self, iteration: int, action_results: List[Dict], user_id: str) -> str:
        """æ„å»ºSystem Prompt

        Args:
            iteration: å½“å‰å¾ªç¯æ¬¡æ•°
            action_results: ä¸Šä¸€è½®å·¥å…·æ‰§è¡Œç»“æœ
            user_id: å½“å‰ç”¨æˆ·IDï¼ˆä»configä¸­è·å–ï¼‰
        """

        # å¦‚æœæœ‰ä¸Šä¸€è½®çš„æ‰§è¡Œç»“æœï¼ŒåŠ å…¥Observation
        observation_text = ""
        if action_results:
            observation_text = "\n\n# ä¸Šä¸€è½®å·¥å…·æ‰§è¡Œç»“æœï¼ˆObservationï¼‰\n"
            for result in action_results:
                status = result.get("status", "unknown")
                tool = result.get("tool", "unknown")
                if status == "success":
                    observation_text += f"- {tool}: âœ“ æˆåŠŸ\n"
                elif status == "error":
                    error = result.get("error", "æœªçŸ¥é”™è¯¯")
                    observation_text += f"- {tool}: âœ— å¤±è´¥ ({error})\n"

            # âš¡ å¢åŠ æŒ‡å¯¼ï¼šè¦æ±‚ LLM åœ¨å›å¤ä¸­ç¡®è®¤å·²å®Œæˆçš„æ“ä½œ
            observation_text += """\nâš ï¸ é‡è¦æç¤ºï¼š
- å¦‚æœå·¥å…·æ‰§è¡ŒæˆåŠŸï¼Œåœ¨ç»™ç”¨æˆ·çš„å›å¤ä¸­è¦**æ˜ç¡®ç¡®è®¤**å·²å®Œæˆçš„æ“ä½œï¼ˆä¾‹å¦‚ï¼š"å·²ä¿å­˜XXä¿¡æ¯"ï¼‰
- ä¸è¦åªè¯´"æœ‰ä»€ä¹ˆéœ€è¦å¸®å¿™çš„"ï¼Œè¦è®©ç”¨æˆ·çŸ¥é“åˆšæ‰çš„æ“ä½œå·²æˆåŠŸå®Œæˆ
- å›å¤è¦è‡ªç„¶ã€å‹å¥½ï¼Œè®©ç”¨æˆ·æ„Ÿå—åˆ°ä»»åŠ¡ç¡®å®å®Œæˆäº†
"""

        # âš ï¸ ä½¿ç”¨åˆ†å±‚ Promptï¼šCONSTITUTIONï¼ˆæ ¸å¿ƒå‡†åˆ™ï¼‰ + MEMORY_GUIDEï¼ˆè®°å¿†ç³»ç»Ÿè¯¦ç»†æŒ‡å—ï¼‰
        prompt = f"""{CONSTITUTION}

{MEMORY_GUIDE}

# å½“å‰ä¸Šä¸‹æ–‡
- å½“å‰ç”¨æˆ· ID: {user_id}
- å½“å‰æ˜¯ç¬¬ {iteration} è½®æ¨ç†
- æœ€å¤§å¾ªç¯æ¬¡æ•°: {AgentConfig.MAX_ITERATIONS}
{observation_text}"""

        return prompt

    def _build_decision(
        self,
        content: str,
        tool_calls: List[Dict],
        iteration: int,
        action_results: List[Dict]
    ) -> Dict:
        """æ ¹æ®LLMè¾“å‡ºæ„å»ºæ ‡å‡†åŒ–çš„decision"""

        # è½¬æ¢tool_callsä¸ºactionsæ ¼å¼
        actions = []
        if tool_calls:
            for call in tool_calls:
                actions.append({
                    "name": call.get("name"),
                    "args": call.get("args", {})
                })

        # åˆ¤æ–­æ˜¯å¦å®Œæˆ
        is_complete = False
        if not actions:
            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œä»»åŠ¡å®Œæˆ
            is_complete = True
        elif iteration >= AgentConfig.MAX_ITERATIONS:
            # è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°
            is_complete = True
            logger.warning("è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°", iteration=iteration)

        # æ„å»ºthinkï¼ˆæ¨ç†è¿‡ç¨‹ï¼‰
        think = f"ç¬¬{iteration}è½®æ¨ç†ï¼š"
        if actions:
            think += f"éœ€è¦è°ƒç”¨{len(actions)}ä¸ªå·¥å…·"
        else:
            think += "ç›´æ¥å›å¤ç”¨æˆ·"

        if action_results:
            think += f"ï¼Œä¸Šè½®æ‰§è¡Œäº†{len(action_results)}ä¸ªå·¥å…·"

        decision = {
            "think": think,
            "actions": actions,
            "response": content or "å¤„ç†ä¸­...",
            "is_complete": is_complete
        }

        return decision

    # ==================== Node 2: Execution æ‰§è¡Œ ====================

    async def execution_node(self, state: AgentState) -> Dict:
        """
        æ‰§è¡ŒèŠ‚ç‚¹ï¼šè°ƒåº¦å·¥å…·æ‰§è¡Œï¼ˆæ— LLMï¼‰ï¼Œé›†æˆHITLæœºåˆ¶

        è¾“å…¥ï¼š
        - decision: Agentæ¨ç†ç»“æœ
        - messages: éœ€è¦ä»ä¸­æå–tool_callsçš„tool_call_id

        è¾“å‡ºï¼š
        - action_results: å·¥å…·æ‰§è¡Œç»“æœåˆ—è¡¨
        - messages: æ·»åŠ ToolMessageï¼ˆä¾›ä¸‹ä¸€è½®Agentè¯»å–ï¼‰

        HITLæ£€æŸ¥ç‚¹ï¼š
        1. æ‰§è¡Œå‰ï¼šæ£€æŸ¥å‚æ•°å®Œæ•´æ€§ï¼ˆç¼ºå‚è¿½é—®ï¼‰
        2. æ‰§è¡Œå‰ï¼šæ£€æŸ¥é«˜é£é™©æ“ä½œï¼ˆç¡®è®¤ï¼‰
        3. æ‰§è¡Œåï¼šæ£€æŸ¥å€™é€‰åˆ—è¡¨ï¼ˆé€‰æ‹©ï¼‰
        """
        decision = state.get("decision", {})
        actions = decision.get("actions", [])
        messages = state.get("messages", [])
        total_tool_calls = state.get("total_tool_calls", 0)

        if not actions:
            logger.info("æ— å·¥å…·éœ€è¦æ‰§è¡Œï¼Œè·³è¿‡")
            return {"action_results": []}

        # æ‰¾åˆ°æœ€åä¸€ä¸ªAIMessageï¼Œæå–tool_calls
        last_ai_message = None
        for msg in reversed(messages):
            if isinstance(msg, AIMessage):
                last_ai_message = msg
                break

        # æå–tool_callsï¼ˆåŒ…å«tool_call_idï¼‰
        tool_calls = getattr(last_ai_message, "tool_calls", []) if last_ai_message else []

        # âš¡ ä»æ¶ˆæ¯å†å²ä¸­æå–å·²æ‰§è¡Œçš„å·¥å…·IDï¼ˆé€šè¿‡æ£€æŸ¥ToolMessageï¼‰
        executed_tool_ids = set()
        for msg in messages:
            if isinstance(msg, ToolMessage):
                executed_tool_ids.add(msg.tool_call_id)

        logger.info(
            f"ğŸ“‹ æ‰§è¡Œå‰çŠ¶æ€æ£€æŸ¥",
            total_actions=len(actions),
            executed_count=len(executed_tool_ids),
            executed_ids=list(executed_tool_ids)
        )
        logger.info(f"å¼€å§‹æ‰§è¡Œ {len(actions)} ä¸ªå·¥å…·ï¼ˆå·²æ‰§è¡Œ: {len(executed_tool_ids)} ä¸ªï¼‰")

        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœªæ‰§è¡Œçš„å·¥å…·
        for i, action in enumerate(actions):
            tool_name = action.get("name")
            tool_args = action.get("args", {})
            tool_call_id = tool_calls[i].get("id") if i < len(tool_calls) else f"call_{i}"

            # æ£€æŸ¥è¯¥å·¥å…·æ˜¯å¦å·²æ‰§è¡Œ
            if tool_call_id in executed_tool_ids:
                logger.info(
                    "â­ï¸ å·¥å…·å·²æ‰§è¡Œï¼Œè·³è¿‡",
                    tool_name=tool_name,
                    tool_call_id=tool_call_id
                )
                continue

            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœªæ‰§è¡Œçš„å·¥å…·
            logger.info(
                "ğŸ› ï¸ å·¥å…·è°ƒç”¨",
                tool_name=tool_name,
                args=tool_args,
                tool_call_id=tool_call_id
            )

            # æ‰§è¡Œ HITL æ£€æŸ¥ï¼ˆå¯èƒ½ä¼š interrupt å¹¶é˜»å¡ï¼Œç­‰å¾…ç”¨æˆ·å“åº”ï¼‰
            hitl_result = await self._check_hitl_requirements(
                tool_name, tool_args, tool_call_id
            )

            # å¦‚æœç”¨æˆ·å–æ¶ˆ
            if hitl_result == "cancelled":
                return {
                    "action_results": [{
                        "tool": tool_name,
                        "status": "cancelled",
                        "error": "ç”¨æˆ·å–æ¶ˆ"
                    }],
                    "messages": [
                        ToolMessage(content="ç”¨æˆ·å–æ¶ˆäº†æ“ä½œ", tool_call_id=tool_call_id)
                    ]
                }

            # HITL æ£€æŸ¥é€šè¿‡ï¼ˆæˆ–ä¸éœ€è¦ï¼‰ï¼Œæ‰§è¡Œå·¥å…·
            # hitl_result æ˜¯æ›´æ–°åçš„ tool_argsï¼ˆå¦‚æœæœ‰ç¼ºå‚è¿½é—®çš„è¯ï¼‰
            result, tool_message = await self._execute_tool_directly(
                tool_name, hitl_result, tool_call_id
            )

            # æ›´æ–°è®¡æ•°
            if result.get("status") in ["success", "error"]:
                total_tool_calls += 1

            logger.info(
                f"å·¥å…·æ‰§è¡Œå®Œæˆï¼Œæœ¬æ¬¡æ‰§è¡Œ 1 ä¸ªï¼Œç´¯è®¡ {total_tool_calls}/{AgentConfig.MAX_TOTAL_TOOL_CALLS}"
            )

            # ç«‹å³è¿”å›ï¼Œç¡®ä¿ç»“æœæŒä¹…åŒ–
            return {
                "action_results": [result],
                "messages": [tool_message],
                "total_tool_calls": total_tool_calls
            }

        # æ‰€æœ‰å·¥å…·éƒ½å·²æ‰§è¡Œ
        logger.info("æ‰€æœ‰å·¥å…·éƒ½å·²æ‰§è¡Œï¼Œæ— éœ€é‡å¤æ‰§è¡Œ")
        return {"action_results": []}

    async def _check_hitl_requirements(
        self, tool_name: str, tool_args: dict, tool_call_id: str
    ):
        """æ£€æŸ¥ HITL è¦æ±‚ï¼ˆç¼ºå‚è¿½é—®ã€é«˜é£é™©ç¡®è®¤ï¼‰

        Returns:
            - tool_args (dict): æ›´æ–°åçš„å‚æ•°ï¼ˆå¦‚æœæœ‰ç¼ºå‚è¿½é—®ï¼‰
            - "cancelled": ç”¨æˆ·å–æ¶ˆ
        """
        # ===== HITLæ£€æŸ¥ç‚¹1ï¼šç¼ºå‚è¿½é—® =====
        missing_params = []
        for param_name, param_value in tool_args.items():
            is_empty = (
                param_value is None or
                (isinstance(param_value, str) and not param_value.strip())
            )
            if is_empty and get_missing_param_prompt(tool_name, param_name):
                missing_params.append(param_name)

        if missing_params:
            logger.info(f"å‚æ•°ç¼ºå¤±: {missing_params}ï¼Œè§¦å‘è¿½é—®")
            prompts = []
            for param in missing_params:
                prompt = get_missing_param_prompt(tool_name, param)
                prompts.append(prompt if prompt else f"è¯·æä¾› {param}")

            user_response = interrupt({
                "type": "ask_params",
                "tool_name": tool_name,
                "missing_params": missing_params,
                "message": "\n".join(prompts),
                "current_args": tool_args
            })

            if isinstance(user_response, dict) and "params" in user_response:
                tool_args.update(user_response["params"])
                logger.info(f"ç”¨æˆ·è¡¥å……å‚æ•°: {user_response['params']}")
            elif user_response == "cancel":
                logger.info("ç”¨æˆ·å–æ¶ˆæ“ä½œ")
                return "cancelled"

        # ===== HITLæ£€æŸ¥ç‚¹2ï¼šé«˜é£é™©æ“ä½œç¡®è®¤ =====
        if need_confirmation(tool_name):
            confirm_msg = get_confirmation_message(tool_name, tool_args)
            logger.info(f"é«˜é£é™©æ“ä½œï¼Œéœ€è¦ç¡®è®¤: {tool_name}")

            user_response = interrupt({
                "type": "confirmation",
                "tool_name": tool_name,
                "args": tool_args,
                "message": confirm_msg,
                "options": ["ç¡®è®¤", "å–æ¶ˆ"]
            })

            if user_response == "cancel" or user_response == "å–æ¶ˆ":
                logger.info("ç”¨æˆ·å–æ¶ˆé«˜é£é™©æ“ä½œ")
                return "cancelled"

            logger.info("ç”¨æˆ·ç¡®è®¤æ“ä½œï¼Œç»§ç»­æ‰§è¡Œ")

        return tool_args

    async def _execute_tool_directly(
        self, tool_name: str, tool_args: dict, tool_call_id: str
    ) -> tuple[dict, ToolMessage]:
        """ç›´æ¥æ‰§è¡Œå·¥å…·ï¼ˆä¸åš HITL æ£€æŸ¥ï¼Œä½†åŒ…å«å€™é€‰åˆ—è¡¨é€‰æ‹©ï¼‰

        Returns:
            (result_dict, tool_message): å·¥å…·æ‰§è¡Œç»“æœå’ŒToolMessage
        """
        try:
            tool = self._find_tool(tool_name)
            if not tool:
                error_msg = f"å·¥å…·ä¸å­˜åœ¨: {tool_name}"
                return (
                    {"tool": tool_name, "status": "error", "error": error_msg},
                    ToolMessage(content=error_msg, tool_call_id=tool_call_id)
                )

            result = await tool.ainvoke(tool_args)
            result_str = str(result)

            logger.info(
                "ğŸ”§ å·¥å…·è¿”å›å€¼",
                tool_name=tool_name,
                result=result_str[:500] if len(result_str) > 500 else result_str,
                result_length=len(result_str)
            )

            # ===== HITLæ£€æŸ¥ç‚¹3ï¼šå€™é€‰åˆ—è¡¨é€‰æ‹© =====
            is_list, candidates = is_candidate_list(result)
            if is_list and need_selection(tool_name):
                selection_msg = get_selection_message(tool_name, len(candidates))
                logger.info(f"æ£€æµ‹åˆ°å€™é€‰åˆ—è¡¨ï¼Œéœ€è¦ç”¨æˆ·é€‰æ‹©: {len(candidates)} ä¸ª")

                formatted_candidates = []
                for idx, item in enumerate(candidates):
                    if isinstance(item, dict):
                        formatted_candidates.append({
                            "id": idx + 1,
                            "name": item.get("mName", item.get("name", str(item))),
                            "description": item.get("mAddress", item.get("description", "")),
                            "raw": item
                        })
                    else:
                        formatted_candidates.append({
                            "id": idx + 1,
                            "name": str(item),
                            "description": "",
                            "raw": item
                        })

                user_response = interrupt({
                    "type": "selection",
                    "tool_name": tool_name,
                    "message": selection_msg,
                    "candidates": formatted_candidates
                })

                if isinstance(user_response, dict) and "selected" in user_response:
                    selected_item = user_response["selected"]
                    result_str = json.dumps(selected_item, ensure_ascii=False)
                    logger.info(f"ç”¨æˆ·é€‰æ‹©: {selected_item.get('name', 'unknown')}")

            logger.info(f"å·¥å…·æ‰§è¡ŒæˆåŠŸ: {tool_name}")
            return (
                {"tool": tool_name, "status": "success", "result": result_str},
                ToolMessage(content=result_str, tool_call_id=tool_call_id)
            )

        except Exception as e:
            error_msg = f"æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(f"å·¥å…·æ‰§è¡Œå¤±è´¥: {tool_name}", error=str(e))
            return (
                {"tool": tool_name, "status": "error", "error": str(e)},
                ToolMessage(content=error_msg, tool_call_id=tool_call_id)
            )

    def _find_tool(self, tool_name: str):
        """æŸ¥æ‰¾å·¥å…·

        ä¼˜å…ˆä» self.tools æŸ¥æ‰¾ï¼ˆAgentå¯ç”¨å·¥å…·ï¼‰
        å¦‚æœæ˜¯ä¿å­˜å·¥å…·ï¼Œä» _all_memory_tools æŸ¥æ‰¾ï¼ˆexecutionèŠ‚ç‚¹ä¸“ç”¨ï¼‰
        """
        # å…ˆä»æ ‡å‡†å·¥å…·åˆ—è¡¨æŸ¥æ‰¾
        for tool in self.tools:
            if tool.name == tool_name:
                return tool

        # å¦‚æœæ˜¯ä¿å­˜å·¥å…·ï¼Œä»å®Œæ•´è®°å¿†å·¥å…·åˆ—è¡¨æŸ¥æ‰¾
        if tool_name in {"memory_save_user_profile", "memory_save_relationship"}:
            if hasattr(self, '_all_memory_tools'):
                for tool in self._all_memory_tools:
                    if tool.name == tool_name:
                        return tool

        return None

    # ==================== Node 3: Response å“åº” ====================

    async def response_node(self, state: AgentState) -> Dict:
        """
        å“åº”èŠ‚ç‚¹ï¼šæ ¼å¼åŒ–æœ€ç»ˆè¾“å‡º

        è¾“å…¥ï¼š
        - decision: Agentæ¨ç†ç»“æœ
        - action_results: å·¥å…·æ‰§è¡Œç»“æœ
        - iteration_count: å¾ªç¯æ¬¡æ•°
        - total_tool_calls: å…¨å±€å·¥å…·è°ƒç”¨æ¬¡æ•°

        è¾“å‡ºï¼š
        - messages: æ·»åŠ æœ€ç»ˆçš„AIå›å¤
        """
        decision = state.get("decision", {})
        action_results = state.get("action_results", [])
        iteration_count = state.get("iteration_count", 0)
        total_tool_calls = state.get("total_tool_calls", 0)

        # æ£€æŸ¥æ˜¯å¦å› è¾¾åˆ°é™åˆ¶è€Œç»ˆæ­¢
        terminate_reason = None
        if iteration_count >= AgentConfig.MAX_ITERATIONS:
            terminate_reason = "max_iterations"
        elif total_tool_calls >= AgentConfig.MAX_TOTAL_TOOL_CALLS:
            terminate_reason = "max_tool_calls"

        # å¦‚æœæ˜¯å› è¾¾åˆ°é™åˆ¶ç»ˆæ­¢ï¼Œç”Ÿæˆå‹å¥½çš„ç»ˆæ­¢æ¶ˆæ¯
        if terminate_reason:
            if terminate_reason == "max_iterations":
                final_response = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†å¤æ‚æƒ…å†µï¼Œå·²è¶…è¿‡æœ€å¤§æ¨ç†æ¬¡æ•°ï¼ˆ{AgentConfig.MAX_ITERATIONS}æ¬¡ï¼‰ã€‚è¯·ç®€åŒ–é—®é¢˜æˆ–é‡æ–°æé—®ã€‚"
            else:  # max_tool_calls
                final_response = f"æŠ±æ­‰ï¼Œæœ¬è½®å¯¹è¯å·²è¾¾åˆ°å·¥å…·è°ƒç”¨æ¬¡æ•°ä¸Šé™ï¼ˆ{AgentConfig.MAX_TOTAL_TOOL_CALLS}æ¬¡ï¼‰ã€‚è¯·å¼€å§‹æ–°çš„å¯¹è¯ã€‚"

            logger.warning(
                "è¾¾åˆ°é™åˆ¶ï¼Œç”Ÿæˆç»ˆæ­¢æ¶ˆæ¯",
                reason=terminate_reason,
                iteration_count=iteration_count,
                total_tool_calls=total_tool_calls
            )
        else:
            # æ­£å¸¸å®Œæˆï¼Œä½¿ç”¨Agentçš„å›å¤
            base_response = decision.get("response", "")

            # âš ï¸ é™é»˜å·¥å…·åˆ—è¡¨ï¼ˆä¸å‘ç”¨æˆ·æ˜¾ç¤ºæ‰§è¡Œç»“æœï¼‰
            # è¿™äº›å·¥å…·çš„æ‰§è¡Œç»“æœæ˜¯æŠ€æœ¯æ€§çš„ï¼Œç”¨æˆ·ä¸éœ€è¦çœ‹åˆ°
            SILENT_TOOLS = {
                "memory_save_location",      # åœ°å€ä¿å­˜
                "memory_save_preference",    # åå¥½ä¿å­˜
                "memory_save_user_profile",  # ç”¨æˆ·ç”»åƒä¿å­˜
                "memory_save_relationship",  # å…³ç³»ç½‘ç»œä¿å­˜
            }

            # å¦‚æœæœ‰å·¥å…·æ‰§è¡Œç»“æœï¼Œåªæ˜¾ç¤ºéé™é»˜å·¥å…·çš„ç»“æœ
            if action_results:
                # è¿‡æ»¤å‡ºéœ€è¦æ˜¾ç¤ºçš„å·¥å…·ç»“æœ
                visible_results = [
                    result for result in action_results
                    if result.get("tool") not in SILENT_TOOLS
                ]

                if visible_results:
                    result_summary = "\n\næ‰§è¡Œç»“æœï¼š\n"
                    for result in visible_results:
                        tool = result.get("tool")
                        status = result.get("status")
                        if status == "success":
                            result_summary += f"âœ“ {tool}: æˆåŠŸ\n"
                        else:
                            error = result.get("error", "æœªçŸ¥é”™è¯¯")
                            result_summary += f"âœ— {tool}: å¤±è´¥ ({error})\n"

                    final_response = base_response + result_summary
                else:
                    # æ‰€æœ‰å·¥å…·éƒ½æ˜¯é™é»˜çš„ï¼Œåªè¿”å› Agent çš„å›å¤
                    final_response = base_response
            else:
                final_response = base_response

        # ğŸ“® è®°å½•æœ€ç»ˆå“åº”
        logger.info(
            "ğŸ“® æœ€ç»ˆå“åº”",
            response=final_response,
            response_length=len(final_response)
        )

        logger.info("ç”Ÿæˆæœ€ç»ˆå“åº”", response_length=len(final_response))

        return {
            "messages": [AIMessage(content=final_response)]
        }

    # ==================== æ¡ä»¶è¾¹ ====================

    def should_continue(self, state: AgentState) -> str:
        """
        åˆ¤æ–­æ˜¯å¦ç»§ç»­ReActå¾ªç¯

        è¿”å›ï¼š
        - "execution": æœ‰å·¥å…·éœ€è¦æ‰§è¡Œï¼Œè¿›å…¥executionèŠ‚ç‚¹
        - "response": ä»»åŠ¡å®Œæˆï¼Œè¿›å…¥responseèŠ‚ç‚¹
        """
        decision = state.get("decision", {})
        total_tool_calls = state.get("total_tool_calls", 0)

        # æ£€æŸ¥å…¨å±€å·¥å…·è°ƒç”¨æ¬¡æ•°
        if total_tool_calls >= AgentConfig.MAX_TOTAL_TOOL_CALLS:
            logger.warning(f"è¾¾åˆ°å…¨å±€å·¥å…·è°ƒç”¨æ¬¡æ•°ä¸Šé™: {total_tool_calls}/{AgentConfig.MAX_TOTAL_TOOL_CALLS}")
            return "response"

        # æ£€æŸ¥æ˜¯å¦å®Œæˆ
        if decision.get("is_complete", False):
            logger.info("ä»»åŠ¡å®Œæˆï¼Œç”Ÿæˆæœ€ç»ˆå“åº”")
            return "response"

        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·éœ€è¦æ‰§è¡Œ
        actions = decision.get("actions", [])
        if actions:
            logger.info(f"æœ‰ {len(actions)} ä¸ªå·¥å…·éœ€è¦æ‰§è¡Œ")
            return "execution"

        # é»˜è®¤ï¼šå®Œæˆ
        return "response"

    def need_continue_after_execution(self, state: AgentState) -> str:
        """
        æ‰§è¡Œå®Œå·¥å…·åï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­å¾ªç¯

        è¿”å›ï¼š
        - "execution": è¿˜æœ‰æœªæ‰§è¡Œçš„å·¥å…·ï¼Œç»§ç»­æ‰§è¡Œ
        - "agent": æ‰€æœ‰å·¥å…·æ‰§è¡Œå®Œæ¯•ï¼Œè¿”å›Agentè¯„ä¼°ç»“æœ
        - "response": ä»»åŠ¡å®Œæˆï¼Œç”Ÿæˆæœ€ç»ˆå“åº”
        """
        iteration = state.get("iteration_count", 0)

        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°
        if iteration >= AgentConfig.MAX_ITERATIONS:
            logger.warning("è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°ï¼Œå¼ºåˆ¶ç»“æŸ", iteration=iteration)
            return "response"

        # âš¡ æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªæ‰§è¡Œçš„å·¥å…·
        decision = state.get("decision", {})
        actions = decision.get("actions", [])
        messages = state.get("messages", [])

        if actions:
            # æå–å·²æ‰§è¡Œçš„ tool_call_ids
            executed_tool_ids = set()
            for msg in messages:
                if isinstance(msg, ToolMessage):
                    executed_tool_ids.add(msg.tool_call_id)

            # æå–æ‰€æœ‰ tool_call_ids
            last_ai_message = None
            for msg in reversed(messages):
                if isinstance(msg, AIMessage):
                    last_ai_message = msg
                    break

            tool_calls = getattr(last_ai_message, "tool_calls", []) if last_ai_message else []
            total_tool_call_ids = {tc.get("id") for tc in tool_calls if tc.get("id")}

            # å¦‚æœè¿˜æœ‰æœªæ‰§è¡Œçš„å·¥å…·ï¼Œç»§ç»­æ‰§è¡Œ
            pending_count = len(total_tool_call_ids - executed_tool_ids)
            if pending_count > 0:
                logger.info(f"è¿˜æœ‰ {pending_count} ä¸ªå·¥å…·æœªæ‰§è¡Œï¼Œç»§ç»­æ‰§è¡Œ")
                return "execution"

        # æ‰€æœ‰å·¥å…·æ‰§è¡Œå®Œæ¯•ï¼Œè¿”å›Agentè¯„ä¼°æ˜¯å¦éœ€è¦ç»§ç»­
        logger.info("æ‰€æœ‰å·¥å…·æ‰§è¡Œå®Œæˆï¼Œè¿”å›Agentè¯„ä¼°æ˜¯å¦éœ€è¦ç»§ç»­")
        return "agent"

    # ==================== æ„å»ºGraph ====================

    def create_graph(self, checkpointer=None):
        """åˆ›å»ºLangGraph

        Args:
            checkpointer: å¯é€‰çš„checkpointerï¼Œç”¨äºæŒä¹…åŒ–å¯¹è¯å†å²
        """

        graph = StateGraph(AgentState)

        # æ·»åŠ èŠ‚ç‚¹
        graph.add_node("agent", self.agent_node)
        graph.add_node("execution", self.execution_node)
        graph.add_node("response", self.response_node)

        # è®¾ç½®å…¥å£
        graph.set_entry_point("agent")

        # Agent â†’ execution æˆ– responseï¼ˆæ¡ä»¶è¾¹ï¼‰
        graph.add_conditional_edges(
            "agent",
            self.should_continue,
            {
                "execution": "execution",
                "response": "response"
            }
        )

        # Execution â†’ execution / agent / responseï¼ˆæ¡ä»¶è¾¹ï¼‰
        # - execution: è¿˜æœ‰æœªæ‰§è¡Œçš„å·¥å…·ï¼Œç»§ç»­æ‰§è¡Œ
        # - agent: æ‰€æœ‰å·¥å…·æ‰§è¡Œå®Œæ¯•ï¼Œè¿”å›Agentè¯„ä¼°
        # - response: è¾¾åˆ°å¾ªç¯ä¸Šé™
        graph.add_conditional_edges(
            "execution",
            self.need_continue_after_execution,
            {
                "execution": "execution",
                "agent": "agent",
                "response": "response"
            }
        )

        # Response â†’ END
        graph.add_edge("response", END)

        # ç¼–è¯‘ï¼ˆå¸¦checkpointerï¼‰
        if checkpointer:
            return graph.compile(checkpointer=checkpointer)
        else:
            return graph.compile()


# ==================== åˆ›å»ºå‡½æ•°ï¼ˆä¾›main.pyè°ƒç”¨ï¼‰ ====================

def create_agent_v2(checkpointer=None):
    """åˆ›å»ºAgent V2å®ä¾‹

    Args:
        checkpointer: LangGraph checkpointer

    Returns:
        ç¼–è¯‘åçš„graph
    """
    agent = NavigationAgentV2()
    return agent.create_graph(checkpointer=checkpointer)
