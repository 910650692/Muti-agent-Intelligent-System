"""å•Agent ReActæ¶æ„å®ç°"""
import asyncio
import json
from typing import List, Any
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage, SystemMessage
from langchain_core.tools import BaseTool
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, END
from langchain_core.messages.tool import ToolCall

from ..state.agent_state import AgentState
from ..llm import get_llm
from ..mcp.manager import mcp_manager
from ..tools.weather_tools import weather_tools
from .system_prompt import get_system_prompt


class NavigationAgent:
    """å¯¼èˆªä¸“ç”¨çš„å•Agent ReActæ¶æ„

    å·¥ä½œæµç¨‹ï¼š
    1. Reasoning: LLMåˆ†æç”¨æˆ·éœ€æ±‚ï¼Œå†³å®šæ˜¯å¦éœ€è¦å·¥å…·
    2. Action: å¹¶è¡Œæ‰§è¡Œå·¥å…·ï¼ˆå¦‚æœéœ€è¦ï¼‰
    3. å¾ªç¯ï¼šè§‚å¯Ÿå·¥å…·ç»“æœï¼Œç»§ç»­æ¨ç†
    4. ç»“æŸï¼šè¾“å‡ºæœ€ç»ˆç­”æ¡ˆ
    """

    def __init__(self, checkpointer=None, memory=None):
        """åˆå§‹åŒ–Agent

        Args:
            checkpointer: LangGraph checkpointerå®ä¾‹ï¼ˆå¦‚AsyncSqliteSaverï¼‰ï¼Œç”¨äºä¿å­˜ä¼šè¯çŠ¶æ€
            memory: Mem0 Memoryå®ä¾‹ï¼Œç”¨äºé•¿æœŸè®°å¿†ç®¡ç†
        """
        print("[NavigationAgent] åˆå§‹åŒ–å•Agent ReActæ¶æ„...")

        self.system_prompt = get_system_prompt()
        self.tools = self._load_all_tools()
        self.checkpointer = checkpointer
        self.memory = memory  # âœ… ä¿å­˜memoryå®ä¾‹
        self.app = self._build_graph()

        print(f"[NavigationAgent] åˆå§‹åŒ–å®Œæˆï¼Œå…±åŠ è½½ {len(self.tools)} ä¸ªå·¥å…·")
        if self.memory:
            print("[NavigationAgent] âœ… Mem0é•¿æœŸè®°å¿†å·²å¯ç”¨")

    def _load_all_tools(self) -> List[BaseTool]:
        """åŠ è½½æ‰€æœ‰å·¥å…·"""
        tools = []

        # 1. åŠ è½½MCPå·¥å…·
        print("[NavigationAgent] æ­£åœ¨åŠ è½½MCPå·¥å…·...")
        mcp_tools = mcp_manager.load_all_tools()
        tools.extend(mcp_tools)
        print(f"[NavigationAgent] åŠ è½½äº† {len(mcp_tools)} ä¸ªMCPå·¥å…·")

        # 2. åŠ è½½å¤©æ°”å·¥å…·
        tools.extend(weather_tools)
        print(f"[NavigationAgent] åŠ è½½äº† {len(weather_tools)} ä¸ªå¤©æ°”å·¥å…·")

        # 3. æœªæ¥å¯ä»¥æ·»åŠ æ›´å¤šå·¥å…·
        # tools.extend(search_tools)

        return tools

    @staticmethod
    def _sanitize_messages_for_text_model(messages: List[BaseMessage]) -> List[BaseMessage]:
        """
        æ¸…ç†æ¶ˆæ¯åˆ—è¡¨ï¼Œå°†å›¾ç‰‡æ›¿æ¢ä¸ºå ä½ç¬¦ï¼Œä¾›æ–‡æœ¬æ¨¡å‹ä½¿ç”¨

        ç›®çš„ï¼š
        - DeepSeekç­‰æ–‡æœ¬æ¨¡å‹ä¸æ”¯æŒ image_url æ ¼å¼ï¼Œä¼šæŠ¥400é”™è¯¯
        - ä½†æˆ‘ä»¬éœ€è¦ä¿ç•™ä¸Šä¸‹æ–‡ï¼Œè®©æ–‡æœ¬æ¨¡å‹çŸ¥é“"è¿™é‡Œæ›¾ç»æœ‰å›¾ç‰‡"

        ç­–ç•¥ï¼š
        - å°† {"type": "image_url", ...} æ›¿æ¢ä¸ºå ä½ç¬¦ "[ç”¨æˆ·å‘é€äº†å›¾ç‰‡]"
        - ä¿ç•™æ‰€æœ‰æ–‡æœ¬å†…å®¹
        - ä¿ç•™æ¶ˆæ¯ç»“æ„å’Œé¡ºåº

        Args:
            messages: åŸå§‹æ¶ˆæ¯åˆ—è¡¨ï¼ˆå¯èƒ½åŒ…å«å›¾ç‰‡ï¼‰

        Returns:
            æ¸…ç†åçš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆçº¯æ–‡æœ¬ + å ä½ç¬¦ï¼‰
        """
        cleaned = []

        for msg in messages:
            # æ£€æŸ¥æ¶ˆæ¯å†…å®¹æ ¼å¼
            if hasattr(msg, 'content') and isinstance(msg.content, list):
                # å¤šæ¨¡æ€æ ¼å¼ï¼ˆåˆ—è¡¨ï¼‰ï¼Œéœ€è¦æå–æ–‡æœ¬å¹¶æ·»åŠ å ä½ç¬¦
                texts = []
                has_image = False

                for item in msg.content:
                    if isinstance(item, dict):
                        if item.get('type') == 'text':
                            # ä¿ç•™æ–‡æœ¬å†…å®¹
                            texts.append(item.get('text', ''))
                        elif item.get('type') in ['image_url', 'image']:
                            # æ£€æµ‹åˆ°å›¾ç‰‡
                            has_image = True

                # é‡å»ºæ¶ˆæ¯å†…å®¹ï¼šå ä½ç¬¦ + æ–‡æœ¬
                text_content = ' '.join(texts).strip()
                if has_image:
                    # åœ¨æ–‡æœ¬å‰æ·»åŠ å ä½ç¬¦
                    text_content = "[ç”¨æˆ·å‘é€äº†å›¾ç‰‡] " + text_content

                # åˆ›å»ºæ–°æ¶ˆæ¯ï¼ˆä¿æŒåŸæ¶ˆæ¯ç±»å‹ï¼‰
                if text_content:
                    # âš ï¸ å…³é”®ä¿®å¤ï¼šå¦‚æœåŸå§‹æ¶ˆæ¯åŒ…å« tool_callsï¼Œéœ€è¦ä¿ç•™
                    # å¦åˆ™ä¼šå¯¼è‡´æ¶ˆæ¯åºåˆ—ä¸åˆæ³•ï¼ˆToolMessage å‰å¿…é¡»æœ‰å¯¹åº”çš„ tool_callsï¼‰
                    if isinstance(msg, AIMessage) and hasattr(msg, 'tool_calls') and msg.tool_calls:
                        new_msg = AIMessage(content=text_content, tool_calls=msg.tool_calls)
                    else:
                        new_msg = msg.__class__(content=text_content)
                    cleaned.append(new_msg)

            else:
                # çº¯æ–‡æœ¬æ¶ˆæ¯æˆ–å…¶ä»–æ ¼å¼ï¼Œç›´æ¥ä¿ç•™
                cleaned.append(msg)

        return cleaned

    def _build_graph(self):
        """æ„å»ºReActå·¥ä½œæµ

        æµç¨‹ï¼š
        reasoning â†’ (éœ€è¦å·¥å…·?)
            â””â”€ æ˜¯ â†’ action â†’ reasoning (å¾ªç¯)
            â””â”€ å¦ â†’ END
        """
        workflow = StateGraph(AgentState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("reasoning", self.call_model)
        workflow.add_node("action", self.call_tools)

        # è®¾ç½®å…¥å£ç‚¹ï¼šç›´æ¥ä»æ¨ç†å¼€å§‹
        workflow.set_entry_point("reasoning")

        # æ¡ä»¶è¾¹ï¼šreasoning â†’ éœ€è¦å·¥å…·ï¼Ÿ
        workflow.add_conditional_edges(
            "reasoning",
            self.should_continue,
            {
                "action": "action",  # éœ€è¦å·¥å…·
                END: END             # ä¸éœ€è¦ï¼Œç»“æŸ
            }
        )

        # å¾ªç¯è¾¹ï¼šaction â†’ reasoningï¼ˆè§‚å¯Ÿç»“æœåç»§ç»­æ€è€ƒï¼‰
        workflow.add_edge("action", "reasoning")

        # âœ… ç¼–è¯‘å·¥ä½œæµï¼Œä¼ å…¥checkpointerä»¥æ”¯æŒä¼šè¯çŠ¶æ€æŒä¹…åŒ–
        return workflow.compile(checkpointer=self.checkpointer)

    async def call_model(self, state: AgentState, config: RunnableConfig | None = None) -> dict:
        """æ¨ç†èŠ‚ç‚¹ï¼šLLMåˆ†æå’Œå†³ç­–

        æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
        1. å•é˜¶æ®µæ¨ç†ï¼ˆçº¯æ–‡æœ¬ï¼‰ï¼šæ–‡æœ¬æ¨¡å‹+å·¥å…·
        2. ä¸¤é˜¶æ®µæ¨ç†ï¼ˆå¤šæ¨¡æ€ï¼‰ï¼š
           - é˜¶æ®µ1: VLæ¨¡å‹ç†è§£å›¾ç‰‡
           - é˜¶æ®µ2: æ–‡æœ¬æ¨¡å‹åŸºäºç†è§£ç»“æœè°ƒç”¨å·¥å…·

        Args:
            state: å½“å‰çŠ¶æ€
            config: è¿è¡Œé…ç½®

        Returns:
            åŒ…å«æ–°æ¶ˆæ¯çš„å­—å…¸
        """
        messages = state["messages"]

        print(f"\n[Reasoning] å¼€å§‹æ¨ç†ï¼Œå½“å‰æ¶ˆæ¯æ•°: {len(messages)}")

        # âœ… æ™ºèƒ½é€‰æ‹©LLMï¼ˆè‡ªåŠ¨æ£€æµ‹æ˜¯å¦æœ‰å›¾ç‰‡ï¼‰
        from ..llm import has_image_content, _extract_text_from_message, _check_message_has_image

        # âœ… æŸ¥è¯¢Mem0é•¿æœŸè®°å¿†
        memory_context = ""
        if self.memory and config:
            try:
                user_id = config.get("configurable", {}).get("user_id", "default")

                # æå–æœ€æ–°ç”¨æˆ·æ¶ˆæ¯
                latest_query = ""
                for msg in reversed(messages):
                    if hasattr(msg, 'type') and msg.type == 'human':
                        latest_query = _extract_text_from_message(msg)
                        break

                if latest_query:
                    # æŸ¥è¯¢ç›¸å…³è®°å¿†ï¼ˆé™åˆ¶5æ¡ï¼‰
                    relevant_memories = self.memory.search(
                        query=latest_query,
                        user_id=user_id,
                        limit=5
                    )

                    # âœ… è°ƒè¯•ï¼šæ‰“å°è¿”å›ç±»å‹
                    print(f"[Memory DEBUG] æŸ¥è¯¢è¿”å›ç±»å‹: {type(relevant_memories)}")
                    print(f"[Memory DEBUG] æŸ¥è¯¢è¿”å›å†…å®¹: {relevant_memories}")

                    if relevant_memories:
                        # âœ… å…¼å®¹ä¸åŒçš„è¿”å›æ ¼å¼
                        memory_facts = []

                        # å¦‚æœè¿”å›çš„æ˜¯ {'results': [...]}
                        if isinstance(relevant_memories, dict) and 'results' in relevant_memories:
                            results = relevant_memories['results']

                            for m in results:
                                if isinstance(m, dict):
                                    # å°è¯•å¤šä¸ªå¯èƒ½çš„å­—æ®µå
                                    fact = (m.get('memory') or
                                           m.get('text') or
                                           m.get('content') or
                                           m.get('data') or
                                           str(m))
                                    if fact and fact != str(m):
                                        memory_facts.append(fact)
                                elif isinstance(m, str):
                                    memory_facts.append(m)

                        # å¦‚æœæ˜¯åˆ—è¡¨ï¼ˆæ—§æ ¼å¼å…¼å®¹ï¼‰
                        elif isinstance(relevant_memories, list):
                            for m in relevant_memories:
                                if isinstance(m, dict):
                                    fact = m.get('memory', '') or m.get('text', '') or m.get('content', '')
                                    if fact:
                                        memory_facts.append(fact)
                                elif isinstance(m, str):
                                    memory_facts.append(m)

                        if memory_facts:
                            memory_context = "\n".join(f"- {fact}" for fact in memory_facts)
                            print(f"[Memory] æŸ¥è¯¢åˆ° {len(memory_facts)} æ¡ç›¸å…³è®°å¿†")
                        else:
                            print(f"[Memory] æŸ¥è¯¢è¿”å›ç©ºç»“æœï¼ˆå¯èƒ½æ²¡æœ‰ç›¸å…³è®°å¿†æˆ–è®°å¿†æœªä¿å­˜æˆåŠŸï¼‰")
            except Exception as e:
                print(f"[Memory] æŸ¥è¯¢å¤±è´¥ï¼ˆé™çº§ä¸ºæ— è®°å¿†æ¨¡å¼ï¼‰: {e}")
                import traceback
                traceback.print_exc()

        # åˆ¤æ–­æ˜¯å¦éœ€è¦å¤šæ¨¡æ€æ¨ç†
        # æ¡ä»¶ï¼šæœ€æ–°æ¶ˆæ¯æ˜¯ HumanMessage ä¸”åŒ…å«å›¾ç‰‡
        # æ’é™¤ï¼šReActå¾ªç¯ä¸­çš„ ToolMessageï¼ˆå·¥å…·è¿”å›ç»“æœåçš„æ¨ç†ï¼‰
        latest_message = messages[-1] if messages else None
        is_latest_human_with_image = (
            latest_message and
            hasattr(latest_message, 'type') and
            latest_message.type == 'human' and
            _check_message_has_image(latest_message)
        )

        # ==================== ä¸¤é˜¶æ®µæ¨ç†ï¼ˆå¤šæ¨¡æ€åœºæ™¯ï¼‰ ====================
        if is_latest_human_with_image:
            print("[Reasoning] ğŸ”„ å¯åŠ¨æ™ºèƒ½ä¸¤é˜¶æ®µæ¨ç†")

            # === é˜¶æ®µ1: è§†è§‰ç†è§£ + æ„å›¾åˆ¤æ–­ ===
            print("[Reasoning] ğŸ“· é˜¶æ®µ1: ä½¿ç”¨VLæ¨¡å‹ç†è§£å›¾ç‰‡å¹¶åˆ¤æ–­æ„å›¾")
            vl_model = get_llm(messages=messages, force_vision=True)

            # å¢å¼ºçš„System Promptï¼šè®©VLæ¨¡å‹è‡ªä¸»åˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·
            vision_system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è§†è§‰åŠ©æ‰‹ã€‚è¯·åˆ†æå›¾ç‰‡å†…å®¹å¹¶ç†è§£ç”¨æˆ·éœ€æ±‚ã€‚

**ä»»åŠ¡ï¼š**
1. è¯¦ç»†æè¿°å›¾ç‰‡ä¸­çš„å†…å®¹ï¼ˆåŒ…æ‹¬æ–‡å­—ã€ç‰©ä½“ã€åœºæ™¯ç­‰å…³é”®ä¿¡æ¯ï¼‰
2. ç†è§£ç”¨æˆ·çš„çœŸå®æ„å›¾

**æ„å›¾åˆ¤æ–­ï¼š**
- å¦‚æœç”¨æˆ·åªæ˜¯æƒ³äº†è§£å›¾ç‰‡å†…å®¹ï¼ˆå¦‚"è¿™æ˜¯ä»€ä¹ˆ"ã€"è¯†åˆ«ä¸€ä¸‹"ã€"æœ‰å‡ ä¸ª"ç­‰ï¼‰ï¼Œç›´æ¥å›ç­”å³å¯
- å¦‚æœç”¨æˆ·éœ€è¦æ‰§è¡Œå…·ä½“æ“ä½œï¼ˆå¦‚"å¯¼èˆªåˆ°è¿™é‡Œ"ã€"æŸ¥è¯¢ä¿¡æ¯"ã€"å¸®æˆ‘è®¢ç¥¨"ã€"æœç´¢é™„è¿‘"ç­‰ï¼‰ï¼Œè¯·åœ¨å›ç­”æœ€åæ·»åŠ æ ‡è®°ï¼š[NEED_TOOLS]

**ç¤ºä¾‹ï¼š**
ç”¨æˆ·ï¼š"è¿™æ˜¯ä»€ä¹ˆï¼Ÿ" â†’ å›ç­”ï¼š"è¿™æ˜¯ä¸¤åªå¯çˆ±çš„å°çŒ«å’ª"ï¼ˆä¸åŠ æ ‡è®°ï¼‰
ç”¨æˆ·ï¼š"å¯¼èˆªåˆ°è¿™é‡Œ" â†’ å›ç­”ï¼š"è¿™æ˜¯å»¶å®‰é«˜æ¶è™¹æ¡¥æ¢çº½å‡ºå£ [NEED_TOOLS]"ï¼ˆæ·»åŠ æ ‡è®°ï¼‰
ç”¨æˆ·ï¼š"å¸®æˆ‘æŸ¥é™„è¿‘åŠ æ²¹ç«™" â†’ å›ç­”ï¼š"å›¾ç‰‡æ˜¾ç¤ºå½“å‰ä½ç½®åœ¨å¸‚ä¸­å¿ƒåŒºåŸŸ [NEED_TOOLS]"ï¼ˆæ·»åŠ æ ‡è®°ï¼‰
"""
            # âœ… æ³¨å…¥Mem0è®°å¿†
            if memory_context:
                vision_system_prompt += f"""

**ç”¨æˆ·é•¿æœŸè®°å¿†**ï¼š
{memory_context}

è¯·ç»“åˆç”¨æˆ·çš„é•¿æœŸè®°å¿†æä¾›ä¸ªæ€§åŒ–æœåŠ¡ã€‚
"""

            # æ„å»ºè§†è§‰ç†è§£çš„æ¶ˆæ¯ï¼ˆåŒ…å«å›¾ç‰‡ï¼‰
            vision_messages = [
                SystemMessage(content=vision_system_prompt),
                *messages
            ]

            # VLæ¨¡å‹æ¨ç†ï¼ˆä¸ç»‘å®šå·¥å…·ï¼‰
            vision_chunk = None
            async for chunk in vl_model.astream(vision_messages, config=config):
                vision_chunk = chunk if vision_chunk is None else (vision_chunk + chunk)

            if vision_chunk is None:
                print("[Reasoning] âš ï¸ é˜¶æ®µ1å¤±è´¥ï¼šVLæ¨¡å‹æœªè¿”å›å†…å®¹")
                return {
                    "messages": [AIMessage(content="æŠ±æ­‰ï¼Œæ— æ³•è¯†åˆ«å›¾ç‰‡å†…å®¹ï¼Œè¯·é‡æ–°ä¸Šä¼ ã€‚")]
                }

            vision_understanding = getattr(vision_chunk, "content", "") or ""
            print(f"[Reasoning] âœ… é˜¶æ®µ1å®Œæˆï¼Œå›¾ç‰‡ç†è§£: {vision_understanding[:100]}...")

            # æ£€æµ‹æ˜¯å¦éœ€è¦è¿›å…¥é˜¶æ®µ2ï¼ˆå¤šç§æ£€æµ‹æ–¹å¼ï¼‰
            TOOL_MARKER = "[NEED_TOOLS]"
            # âœ… å¢å¼ºæ£€æµ‹ï¼šä¸ä»…æ£€æŸ¥æ ‡è®°ï¼Œè¿˜æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨ç›¸å…³å…³é”®è¯
            TOOL_KEYWORDS = ["<tool_call>", "tool_call", "è§„åˆ’è·¯çº¿", "æœç´¢", "æŸ¥è¯¢", "è®¢ç¥¨", "å¯¼èˆª"]
            needs_tools = (
                TOOL_MARKER in vision_understanding or
                any(keyword in vision_understanding for keyword in TOOL_KEYWORDS)
            )

            if not needs_tools:
                # çº¯å›¾ç‰‡é—®ç­”ï¼Œç›´æ¥è¿”å›VLæ¨¡å‹çš„å›ç­”
                print("[Reasoning] ğŸ’¬ åˆ¤æ–­ï¼šçº¯å›¾ç‰‡é—®ç­”ï¼Œæ— éœ€å·¥å…·ï¼Œç›´æ¥è¿”å›")
                content = vision_understanding
                tool_calls = None
            else:
                # éœ€è¦å·¥å…·ï¼Œè¿›å…¥é˜¶æ®µ2
                print("[Reasoning] ğŸ› ï¸  åˆ¤æ–­ï¼šéœ€è¦æ‰§è¡Œæ“ä½œï¼Œè¿›å…¥é˜¶æ®µ2")

                # å»æ‰å·¥å…·ç›¸å…³æ ‡è®°å’Œæ ‡ç­¾ï¼Œä¿ç•™çº¯å‡€çš„ç†è§£ç»“æœ
                import re
                vision_understanding_clean = vision_understanding.replace(TOOL_MARKER, "")
                # å»æ‰ <tool_call>...</tool_call> æ ‡ç­¾
                vision_understanding_clean = re.sub(r'<tool_call>.*?</tool_call>', '', vision_understanding_clean, flags=re.DOTALL)
                vision_understanding_clean = vision_understanding_clean.strip()
                print(f"[Reasoning] æ¸…ç†åçš„ç†è§£: {vision_understanding_clean[:100]}...")

                # === é˜¶æ®µ2: ä»»åŠ¡æ‰§è¡Œï¼ˆæ–‡æœ¬æ¨¡å‹+å·¥å…·ï¼‰ ===
                print("[Reasoning] ğŸ› ï¸  é˜¶æ®µ2: ä½¿ç”¨æ–‡æœ¬æ¨¡å‹+å·¥å…·æ‰§è¡Œä»»åŠ¡")
                text_model = get_llm(force_text=True)
                model_with_tools = text_model.bind_tools(self.tools)

                # æå–æœ€æ–°ç”¨æˆ·æ¶ˆæ¯çš„æ–‡æœ¬éƒ¨åˆ†ï¼ˆç”¨æˆ·çš„åŸå§‹é—®é¢˜ï¼‰
                latest_user_text = ""
                for msg in reversed(messages):
                    if hasattr(msg, 'type') and msg.type == 'human':
                        latest_user_text = _extract_text_from_message(msg)
                        break

                # æ„å»ºç¬¬äºŒé˜¶æ®µçš„æ¶ˆæ¯ï¼šå†å²ï¼ˆæ¸…ç†å›¾ç‰‡ï¼‰+ å›¾ç‰‡ç†è§£ç»“æœ + ç”¨æˆ·é—®é¢˜
                # æ¸…ç†å†å²æ¶ˆæ¯ä¸­çš„å›¾ç‰‡
                cleaned_history = self._sanitize_messages_for_text_model(messages[:-1]) if len(messages) > 1 else []

                # ç»„åˆæ¶ˆæ¯ï¼šå›¾ç‰‡ç†è§£ + ç”¨æˆ·éœ€æ±‚ï¼ˆä½¿ç”¨æ¸…ç†åçš„ç†è§£ç»“æœï¼‰
                enhanced_message = f"""[å›¾ç‰‡å†…å®¹ç†è§£]
{vision_understanding_clean}

[ç”¨æˆ·éœ€æ±‚]
{latest_user_text if latest_user_text else "è¯·æ ¹æ®å›¾ç‰‡å†…å®¹æä¾›å¸®åŠ©"}"""

                # âœ… æ³¨å…¥Mem0è®°å¿†åˆ°system prompt
                enhanced_system_prompt = self.system_prompt
                if memory_context:
                    enhanced_system_prompt = f"""{self.system_prompt}

**ç”¨æˆ·é•¿æœŸè®°å¿†**ï¼š
{memory_context}

è¯·ç»“åˆç”¨æˆ·çš„é•¿æœŸè®°å¿†æä¾›ä¸ªæ€§åŒ–æœåŠ¡ã€‚
"""

                task_messages = [
                    SystemMessage(content=enhanced_system_prompt),
                    *cleaned_history,
                    HumanMessage(content=enhanced_message)
                ]

                # æ–‡æœ¬æ¨¡å‹æ¨ç†ï¼ˆç»‘å®šå·¥å…·ï¼‰
                task_chunk = None
                async for chunk in model_with_tools.astream(task_messages, config=config):
                    task_chunk = chunk if task_chunk is None else (task_chunk + chunk)

                if task_chunk is None:
                    print("[Reasoning] âš ï¸ é˜¶æ®µ2å¤±è´¥ï¼šæ–‡æœ¬æ¨¡å‹æœªè¿”å›å†…å®¹")
                    return {
                        "messages": [AIMessage(content=vision_understanding_clean)]
                    }

                # æå–æœ€ç»ˆç»“æœ
                content = getattr(task_chunk, "content", "") or ""
                tool_calls = getattr(task_chunk, "tool_calls", None)

                # âœ… ä¿®å¤ç©ºcontenté—®é¢˜ï¼šå¦‚æœLLMåªè¿”å›tool_callsæ²¡æœ‰contentï¼Œç”¨VLç†è§£å¡«å……
                if not content and tool_calls:
                    content = vision_understanding_clean
                    print("[Reasoning] âœ… é˜¶æ®µ2å®Œæˆï¼ˆLLMè¿”å›ç©ºcontentï¼Œä½¿ç”¨VLç†è§£æ–‡æœ¬ï¼‰")
                else:
                    print(f"[Reasoning] âœ… é˜¶æ®µ2å®Œæˆ")

                print(f"[Reasoning DEBUG] å†…å®¹é•¿åº¦: {len(content)}")
                print(f"[Reasoning DEBUG] å†…å®¹é¢„è§ˆ: {content[:100] if content else '(ç©º)'}")

        # ==================== å•é˜¶æ®µæ¨ç†ï¼ˆçº¯æ–‡æœ¬åœºæ™¯ï¼‰ ====================
        else:
            print("[Reasoning] ğŸ“ å•é˜¶æ®µæ¨ç†: çº¯æ–‡æœ¬æ¨¡å¼")
            text_model = get_llm(force_text=True)  # âœ… å¼ºåˆ¶ä½¿ç”¨æ–‡æœ¬æ¨¡å‹ï¼ˆé¿å…å†å²å›¾ç‰‡å¹²æ‰°ï¼‰
            model_with_tools = text_model.bind_tools(self.tools)

            # æ¸…ç†å†å²æ¶ˆæ¯ä¸­çš„å›¾ç‰‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            messages_to_send = self._sanitize_messages_for_text_model(messages)

            # âœ… æ³¨å…¥Mem0è®°å¿†åˆ°system prompt
            enhanced_system_prompt = self.system_prompt
            if memory_context:
                enhanced_system_prompt = f"""{self.system_prompt}

**ç”¨æˆ·é•¿æœŸè®°å¿†**ï¼š
{memory_context}

è¯·ç»“åˆç”¨æˆ·çš„é•¿æœŸè®°å¿†æä¾›ä¸ªæ€§åŒ–æœåŠ¡ã€‚
"""

            # æ„å»ºå®Œæ•´çš„æ¶ˆæ¯
            full_messages = [
                SystemMessage(content=enhanced_system_prompt),
                *messages_to_send
            ]

            # æ¨ç†
            print(f"[Reasoning DEBUG] å‘é€æ¶ˆæ¯ç»™LLMï¼Œæ¶ˆæ¯æ•°: {len(full_messages)}")
            # æ‰“å°æ¶ˆæ¯å†…å®¹æ‘˜è¦
            for i, msg in enumerate(full_messages):
                msg_type = msg.__class__.__name__
                content_preview = str(msg.content)[:100] if hasattr(msg, 'content') else "N/A"
                print(f"[Reasoning DEBUG]   [{i}] {msg_type}: {content_preview}...")

            merged_chunk = None
            try:
                async for chunk in model_with_tools.astream(full_messages, config=config):
                    merged_chunk = chunk if merged_chunk is None else (merged_chunk + chunk)
                print("[Reasoning DEBUG] LLMæµå¼è¾“å‡ºå®Œæˆ")
            except Exception as e:
                print(f"[Reasoning] âš ï¸ LLMè°ƒç”¨å¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
                return {
                    "messages": [AIMessage(content=f"æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {e}")]
                }

            if merged_chunk is None:
                print("[Reasoning] âš ï¸ LLMæœªè¿”å›ä»»ä½•å†…å®¹")
                return {}

            # æå–ç»“æœ
            content = getattr(merged_chunk, "content", "") or ""
            tool_calls = getattr(merged_chunk, "tool_calls", None)

            print(f"[Reasoning DEBUG] LLMè¿”å›å†…å®¹é•¿åº¦: {len(content)}")
            print(f"[Reasoning DEBUG] å†…å®¹é¢„è§ˆ: {content[:100] if content else '(ç©º)'}")

        # ==================== æ„å»ºAIæ¶ˆæ¯ï¼ˆä¸¤ç§æ¨¡å¼å…±ç”¨ï¼‰ ====================
        if not content and not tool_calls:
            print("[Reasoning] âš ï¸ è¿”å›ç©ºå†…å®¹")
            content = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¤„ç†è¿™ä¸ªè¯·æ±‚ã€‚"

        ai_message = AIMessage(
            content=content,
            tool_calls=tool_calls if tool_calls else []
        )

        # æ‰“å°å†³ç­–ä¿¡æ¯
        if tool_calls:
            tool_names = [call["name"] for call in tool_calls]
            print(f"[Reasoning] ğŸ¯ å†³ç­–: éœ€è¦è°ƒç”¨ {len(tool_calls)} ä¸ªå·¥å…·: {tool_names}")
        else:
            print(f"[Reasoning] ğŸ’¬ å†³ç­–: ç›´æ¥å›ç­”ç”¨æˆ·")

        # âœ… ä¿å­˜å¯¹è¯åˆ°Mem0ï¼ˆåªåœ¨æœ‰å®é™…å†…å®¹ä¸”æ— å·¥å…·è°ƒç”¨æ—¶ä¿å­˜ï¼Œé¿å…ä¿å­˜ä¸­é—´çŠ¶æ€ï¼‰
        if self.memory and config and content and not tool_calls:
            try:
                user_id = config.get("configurable", {}).get("user_id", "default")

                # æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘2è½®ï¼‰
                conversation_text = ""
                recent_messages = messages[-2:] if len(messages) >= 2 else messages
                for msg in recent_messages:
                    if hasattr(msg, 'type'):
                        if msg.type == 'human':
                            conversation_text += f"User: {_extract_text_from_message(msg)}\n"
                        elif msg.type == 'ai':
                            msg_content = getattr(msg, 'content', '')
                            if isinstance(msg_content, str) and msg_content:
                                conversation_text += f"Assistant: {msg_content}\n"

                # æ·»åŠ å½“å‰å›å¤
                conversation_text += f"Assistant: {content}"

                # âœ… è°ƒè¯•ï¼šæ‰“å°ä¿å­˜å†…å®¹
                print(f"[Memory DEBUG] å‡†å¤‡ä¿å­˜ï¼Œuser_id={user_id}")
                print(f"[Memory DEBUG] å¯¹è¯å†…å®¹: {conversation_text[:200]}...")

                # ä¿å­˜åˆ°Mem0ï¼ˆMem0ä¼šè‡ªåŠ¨æå–äº‹å®ï¼‰
                result = self.memory.add(
                    messages=conversation_text,
                    user_id=user_id,
                    metadata={"source": "navigation_agent", "timestamp": str(__import__('time').time())}
                )
                print(f"[Memory DEBUG] Mem0è¿”å›ç»“æœ: {result}")
                print(f"[Memory] å·²ä¿å­˜å¯¹è¯è®°å¿†ï¼ˆuser_id={user_id}ï¼‰")
            except Exception as e:
                print(f"[Memory] ä¿å­˜å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")

        return {"messages": [ai_message]}

    async def call_tools(self, state: AgentState) -> dict:
        """æ‰§è¡Œå·¥å…·èŠ‚ç‚¹ï¼šå¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨

        Args:
            state: å½“å‰çŠ¶æ€

        Returns:
            åŒ…å«å·¥å…·ç»“æœçš„å­—å…¸
        """
        last_message = state["messages"][-1]

        if not isinstance(last_message, AIMessage) or not last_message.tool_calls:
            print("[Action] âš ï¸ æ²¡æœ‰å·¥å…·éœ€è¦æ‰§è¡Œ")
            return {}

        tools_map = {tool.name: tool for tool in self.tools}

        async def run_one(call: ToolCall) -> ToolMessage:
            """æ‰§è¡Œå•ä¸ªå·¥å…·è°ƒç”¨"""
            name = call["name"]
            args = call["args"]
            call_id = call["id"]

            print(f"[Action] è°ƒç”¨å·¥å…·: {name}ï¼Œå‚æ•°: {args}")

            # æ£€æŸ¥å·¥å…·æ˜¯å¦å­˜åœ¨
            if name not in tools_map:
                error = {"error": f"æœªçŸ¥å·¥å…· '{name}'"}
                print(f"[Action] âŒ {error['error']}")
                return ToolMessage(
                    content=json.dumps(error, ensure_ascii=False),
                    tool_call_id=call_id
                )

            tool = tools_map[name]

            try:
                # æ‰§è¡Œå·¥å…·ï¼ˆæ”¯æŒå¼‚æ­¥ï¼‰
                result = await asyncio.wait_for(tool.ainvoke(args), timeout=30)

                # è½¬æ¢ç»“æœä¸ºå­—ç¬¦ä¸²
                if isinstance(result, str):
                    content = result
                else:
                    try:
                        content = json.dumps(result, ensure_ascii=False, default=str)
                    except (TypeError, ValueError):
                        content = str(result)

                print(f"[Action] âœ… å·¥å…· {name} æ‰§è¡ŒæˆåŠŸ")
                return ToolMessage(content=content, tool_call_id=call_id)

            except asyncio.TimeoutError:
                error = {"error": f"å·¥å…· '{name}' æ‰§è¡Œè¶…æ—¶ï¼ˆ30ç§’ï¼‰"}
                print(f"[Action] âŒ {error['error']}")
                return ToolMessage(
                    content=json.dumps(error, ensure_ascii=False),
                    tool_call_id=call_id
                )
            except Exception as e:
                error = {"error": f"å·¥å…· '{name}' æ‰§è¡Œå¤±è´¥: {str(e)}"}
                print(f"[Action] âŒ {error['error']}")
                return ToolMessage(
                    content=json.dumps(error, ensure_ascii=False),
                    tool_call_id=call_id
                )

        # âœ… å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
        print(f"[Action] å¼€å§‹å¹¶è¡Œæ‰§è¡Œ {len(last_message.tool_calls)} ä¸ªå·¥å…·...")
        tool_outputs = await asyncio.gather(
            *[run_one(call) for call in last_message.tool_calls]
        )

        print(f"[Action] æ‰€æœ‰å·¥å…·æ‰§è¡Œå®Œæˆ")
        return {"messages": tool_outputs}

    def should_continue(self, state: AgentState) -> str:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­è°ƒç”¨å·¥å…·

        Args:
            state: å½“å‰çŠ¶æ€

        Returns:
            "action" æˆ– END
        """
        last_message = state["messages"][-1]

        # å¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯æ˜¯AIæ¶ˆæ¯ä¸”åŒ…å«å·¥å…·è°ƒç”¨ï¼Œåˆ™æ‰§è¡Œå·¥å…·
        if isinstance(last_message, AIMessage) and last_message.tool_calls:
            return "action"

        # å¦åˆ™ç»“æŸ
        return END

    async def astream_events(self, initial_state: dict, config: dict):
        """æµå¼æ‰§è¡ŒAgentå¹¶è¿”å›äº‹ä»¶

        è¿™æ˜¯ä¸€ä¸ªä¾¿æ·æ–¹æ³•ï¼Œç”¨äºå…¼å®¹ç°æœ‰çš„APIæ¥å£

        Args:
            initial_state: åˆå§‹çŠ¶æ€
            config: é…ç½®

        Yields:
            äº‹ä»¶å­—å…¸
        """
        async for event in self.app.astream_events(initial_state, config, version="v2"):
            yield event


def create_agent(checkpointer=None, memory=None) -> NavigationAgent:
    """åˆ›å»ºAgentå®ä¾‹

    Args:
        checkpointer: LangGraph checkpointerå®ä¾‹
        memory: Mem0 Memoryå®ä¾‹

    Returns:
        NavigationAgentå®ä¾‹
    """
    return NavigationAgent(checkpointer=checkpointer, memory=memory)
