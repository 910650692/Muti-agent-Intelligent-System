"""å•Agent ReActæž¶æž„å®žçŽ°"""
import asyncio
import json
from typing import List, Any
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage, SystemMessage
from langchain_core.tools import BaseTool
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, END
from langchain_core.messages.tool import ToolCall

from ..state.agent_state import AgentState
from ..llm import get_llm
from ..mcp.manager import mcp_manager
from ..tools.weather_tools import weather_tools
from .system_prompt import get_system_prompt


class NavigationAgent:
    """å¯¼èˆªä¸“ç”¨çš„å•Agent ReActæž¶æž„

    å·¥ä½œæµç¨‹ï¼š
    1. Reasoning: LLMåˆ†æžç”¨æˆ·éœ€æ±‚ï¼Œå†³å®šæ˜¯å¦éœ€è¦å·¥å…·
    2. Action: å¹¶è¡Œæ‰§è¡Œå·¥å…·ï¼ˆå¦‚æžœéœ€è¦ï¼‰
    3. å¾ªçŽ¯ï¼šè§‚å¯Ÿå·¥å…·ç»“æžœï¼Œç»§ç»­æŽ¨ç†
    4. ç»“æŸï¼šè¾“å‡ºæœ€ç»ˆç­”æ¡ˆ
    """

    def __init__(self, checkpointer=None):
        """åˆå§‹åŒ–Agent

        Args:
            checkpointer: LangGraph checkpointerå®žä¾‹ï¼ˆå¦‚AsyncSqliteSaverï¼‰ï¼Œç”¨äºŽä¿å­˜ä¼šè¯çŠ¶æ€
        """
        print("[NavigationAgent] åˆå§‹åŒ–å•Agent ReActæž¶æž„...")

        self.system_prompt = get_system_prompt()
        self.tools = self._load_all_tools()
        self.checkpointer = checkpointer
        self.app = self._build_graph()

        print(f"[NavigationAgent] åˆå§‹åŒ–å®Œæˆï¼Œå…±åŠ è½½ {len(self.tools)} ä¸ªå·¥å…·")

    def _load_all_tools(self) -> List[BaseTool]:
        """åŠ è½½æ‰€æœ‰å·¥å…·"""
        tools = []

        # 1. åŠ è½½å¯¼èˆªMCPå·¥å…·
        print("[NavigationAgent] æ­£åœ¨åŠ è½½MCPå¯¼èˆªå·¥å…·...")
        mcp_tools = mcp_manager.load_all_tools()
        navigation_mcp_tools = [
            tool for tool in mcp_tools
            if "sgm-navigation" in tool.name.lower() or "navi" in tool.name.lower()
        ]
        tools.extend(navigation_mcp_tools)
        print(f"[NavigationAgent] åŠ è½½äº† {len(navigation_mcp_tools)} ä¸ªMCPå·¥å…·")

        # 2. åŠ è½½å¤©æ°”å·¥å…·
        tools.extend(weather_tools)
        print(f"[NavigationAgent] åŠ è½½äº† {len(weather_tools)} ä¸ªå¤©æ°”å·¥å…·")

        # 3. æœªæ¥å¯ä»¥æ·»åŠ æ›´å¤šå·¥å…·
        # tools.extend(search_tools)

        return tools

    def _build_graph(self):
        """æž„å»ºReActå·¥ä½œæµ

        æµç¨‹ï¼š
        reasoning â†’ (éœ€è¦å·¥å…·?)
            â””â”€ æ˜¯ â†’ action â†’ reasoning (å¾ªçŽ¯)
            â””â”€ å¦ â†’ END
        """
        workflow = StateGraph(AgentState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("reasoning", self.call_model)
        workflow.add_node("action", self.call_tools)

        # è®¾ç½®å…¥å£ç‚¹ï¼šç›´æŽ¥ä»ŽæŽ¨ç†å¼€å§‹
        workflow.set_entry_point("reasoning")

        # æ¡ä»¶è¾¹ï¼šreasoning â†’ éœ€è¦å·¥å…·ï¼Ÿ
        workflow.add_conditional_edges(
            "reasoning",
            self.should_continue,
            {
                "action": "action",  # éœ€è¦å·¥å…·
                END: END             # ä¸éœ€è¦ï¼Œç»“æŸ
            }
        )

        # å¾ªçŽ¯è¾¹ï¼šaction â†’ reasoningï¼ˆè§‚å¯Ÿç»“æžœåŽç»§ç»­æ€è€ƒï¼‰
        workflow.add_edge("action", "reasoning")

        # âœ… ç¼–è¯‘å·¥ä½œæµï¼Œä¼ å…¥checkpointerä»¥æ”¯æŒä¼šè¯çŠ¶æ€æŒä¹…åŒ–
        return workflow.compile(checkpointer=self.checkpointer)

    async def call_model(self, state: AgentState, config: RunnableConfig | None = None) -> dict:
        """æŽ¨ç†èŠ‚ç‚¹ï¼šLLMåˆ†æžå’Œå†³ç­–

        Args:
            state: å½“å‰çŠ¶æ€
            config: è¿è¡Œé…ç½®

        Returns:
            åŒ…å«æ–°æ¶ˆæ¯çš„å­—å…¸
        """
        messages = state["messages"]

        print(f"\n[Reasoning] å¼€å§‹æŽ¨ç†ï¼Œå½“å‰æ¶ˆæ¯æ•°: {len(messages)}")

        # âœ… æ™ºèƒ½é€‰æ‹©LLMï¼ˆè‡ªåŠ¨æ£€æµ‹æ˜¯å¦æœ‰å›¾ç‰‡ï¼‰
        from ..llm import has_image_content
        is_multimodal = has_image_content(messages)
        llm = get_llm(messages=messages)

        # âœ… å…³é”®ä¿®å¤ï¼šè§†è§‰æ¨¡åž‹ä¸ç»‘å®šå·¥å…·ï¼ˆå¯èƒ½ä¸æ”¯æŒfunction callingï¼‰
        if is_multimodal:
            print("[Reasoning] æ£€æµ‹åˆ°å›¾ç‰‡ï¼Œä½¿ç”¨çº¯è§†è§‰æ¨¡åž‹ï¼ˆä¸ç»‘å®šå·¥å…·ï¼‰")
            model_with_tools = llm  # ä¸ç»‘å®šå·¥å…·
        else:
            print("[Reasoning] çº¯æ–‡æœ¬æ¨¡å¼ï¼Œç»‘å®šæ‰€æœ‰å·¥å…·")
            model_with_tools = llm.bind_tools(self.tools)

        # æž„å»ºå®Œæ•´çš„æ¶ˆæ¯ï¼ˆsystem + historyï¼‰
        full_messages = [
            SystemMessage(content=self.system_prompt),
            *messages
        ]

        # æµå¼æŽ¨ç†å¹¶æ”¶é›†å®Œæ•´å“åº”
        merged_chunk = None
        async for chunk in model_with_tools.astream(full_messages, config=config):
            merged_chunk = chunk if merged_chunk is None else (merged_chunk + chunk)

        if merged_chunk is None:
            print("[Reasoning] âš ï¸ LLMæœªè¿”å›žä»»ä½•å†…å®¹")
            return {}

        # æž„å»ºAIæ¶ˆæ¯
        content = getattr(merged_chunk, "content", "") or ""
        tool_calls = getattr(merged_chunk, "tool_calls", None)

        # ðŸ› è°ƒè¯•ï¼šæ‰“å°LLMè¿”å›žçš„åŽŸå§‹å†…å®¹
        print(f"[Reasoning DEBUG] LLMè¿”å›žå†…å®¹é•¿åº¦: {len(content)}")
        print(f"[Reasoning DEBUG] å†…å®¹é¢„è§ˆ: {content[:100] if content else '(ç©º)'}")

        # âœ… å¦‚æžœLLMè¿”å›žç©ºå†…å®¹ï¼Œç»™å‡ºå‹å¥½æç¤º
        if not content and not tool_calls:
            print("[Reasoning] âš ï¸ LLMè¿”å›žç©ºå†…å®¹ï¼Œå¯èƒ½æ˜¯å›¾ç‰‡æ ¼å¼é—®é¢˜æˆ–APIé”™è¯¯")
            content = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•è¯†åˆ«è¿™å¼ å›¾ç‰‡ã€‚è¯·å°è¯•ï¼š\n1. é‡æ–°ä¸Šä¼ å›¾ç‰‡\n2. ç¡®ä¿å›¾ç‰‡æ¸…æ™°å¯è§\n3. æˆ–è€…ç›´æŽ¥æè¿°æ‚¨çš„é—®é¢˜"

        ai_message = AIMessage(
            content=content,
            tool_calls=tool_calls if tool_calls else []
        )

        # æ‰“å°å†³ç­–ä¿¡æ¯
        if tool_calls:
            tool_names = [call["name"] for call in tool_calls]
            print(f"[Reasoning] å†³ç­–: éœ€è¦è°ƒç”¨ {len(tool_calls)} ä¸ªå·¥å…·: {tool_names}")
        else:
            print(f"[Reasoning] å†³ç­–: ç›´æŽ¥å›žç­”ç”¨æˆ·")

        return {"messages": [ai_message]}

    async def call_tools(self, state: AgentState) -> dict:
        """æ‰§è¡Œå·¥å…·èŠ‚ç‚¹ï¼šå¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨

        Args:
            state: å½“å‰çŠ¶æ€

        Returns:
            åŒ…å«å·¥å…·ç»“æžœçš„å­—å…¸
        """
        last_message = state["messages"][-1]

        if not isinstance(last_message, AIMessage) or not last_message.tool_calls:
            print("[Action] âš ï¸ æ²¡æœ‰å·¥å…·éœ€è¦æ‰§è¡Œ")
            return {}

        tools_map = {tool.name: tool for tool in self.tools}

        async def run_one(call: ToolCall) -> ToolMessage:
            """æ‰§è¡Œå•ä¸ªå·¥å…·è°ƒç”¨"""
            name = call["name"]
            args = call["args"]
            call_id = call["id"]

            print(f"[Action] è°ƒç”¨å·¥å…·: {name}ï¼Œå‚æ•°: {args}")

            # æ£€æŸ¥å·¥å…·æ˜¯å¦å­˜åœ¨
            if name not in tools_map:
                error = {"error": f"æœªçŸ¥å·¥å…· '{name}'"}
                print(f"[Action] âŒ {error['error']}")
                return ToolMessage(
                    content=json.dumps(error, ensure_ascii=False),
                    tool_call_id=call_id
                )

            tool = tools_map[name]

            try:
                # æ‰§è¡Œå·¥å…·ï¼ˆæ”¯æŒå¼‚æ­¥ï¼‰
                result = await asyncio.wait_for(tool.ainvoke(args), timeout=30)

                # è½¬æ¢ç»“æžœä¸ºå­—ç¬¦ä¸²
                if isinstance(result, str):
                    content = result
                else:
                    try:
                        content = json.dumps(result, ensure_ascii=False, default=str)
                    except (TypeError, ValueError):
                        content = str(result)

                print(f"[Action] âœ… å·¥å…· {name} æ‰§è¡ŒæˆåŠŸ")
                return ToolMessage(content=content, tool_call_id=call_id)

            except asyncio.TimeoutError:
                error = {"error": f"å·¥å…· '{name}' æ‰§è¡Œè¶…æ—¶ï¼ˆ30ç§’ï¼‰"}
                print(f"[Action] âŒ {error['error']}")
                return ToolMessage(
                    content=json.dumps(error, ensure_ascii=False),
                    tool_call_id=call_id
                )
            except Exception as e:
                error = {"error": f"å·¥å…· '{name}' æ‰§è¡Œå¤±è´¥: {str(e)}"}
                print(f"[Action] âŒ {error['error']}")
                return ToolMessage(
                    content=json.dumps(error, ensure_ascii=False),
                    tool_call_id=call_id
                )

        # âœ… å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
        print(f"[Action] å¼€å§‹å¹¶è¡Œæ‰§è¡Œ {len(last_message.tool_calls)} ä¸ªå·¥å…·...")
        tool_outputs = await asyncio.gather(
            *[run_one(call) for call in last_message.tool_calls]
        )

        print(f"[Action] æ‰€æœ‰å·¥å…·æ‰§è¡Œå®Œæˆ")
        return {"messages": tool_outputs}

    def should_continue(self, state: AgentState) -> str:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­è°ƒç”¨å·¥å…·

        Args:
            state: å½“å‰çŠ¶æ€

        Returns:
            "action" æˆ– END
        """
        last_message = state["messages"][-1]

        # å¦‚æžœæœ€åŽä¸€æ¡æ¶ˆæ¯æ˜¯AIæ¶ˆæ¯ä¸”åŒ…å«å·¥å…·è°ƒç”¨ï¼Œåˆ™æ‰§è¡Œå·¥å…·
        if isinstance(last_message, AIMessage) and last_message.tool_calls:
            return "action"

        # å¦åˆ™ç»“æŸ
        return END

    async def astream_events(self, initial_state: dict, config: dict):
        """æµå¼æ‰§è¡ŒAgentå¹¶è¿”å›žäº‹ä»¶

        è¿™æ˜¯ä¸€ä¸ªä¾¿æ·æ–¹æ³•ï¼Œç”¨äºŽå…¼å®¹çŽ°æœ‰çš„APIæŽ¥å£

        Args:
            initial_state: åˆå§‹çŠ¶æ€
            config: é…ç½®

        Yields:
            äº‹ä»¶å­—å…¸
        """
        async for event in self.app.astream_events(initial_state, config, version="v2"):
            yield event


def create_agent(checkpointer=None) -> NavigationAgent:
    """åˆ›å»ºAgentå®žä¾‹

    Args:
        checkpointer: LangGraph checkpointerå®žä¾‹

    Returns:
        NavigationAgentå®žä¾‹
    """
    return NavigationAgent(checkpointer=checkpointer)
